{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Marketing AI Agent - Complete Workflow\n",
    "\n",
    "This notebook demonstrates the complete workflow of the Reddit Marketing AI Agent using Haystack RAG.\n",
    "\n",
    "## Workflow Steps:\n",
    "1. **Document Ingestion** - Multiple methods (direct content, URL scraping, file upload)\n",
    "2. **Topic Extraction** - Extract topics from documents using Haystack RAG\n",
    "3. **Subreddit Discovery** - Find and rank relevant subreddits\n",
    "4. **Post Search** - Search for relevant posts in target subreddits\n",
    "5. **Post Analysis** - Analyze posts and comments for engagement opportunities\n",
    "6. **Response Generation** - Generate contextual responses using RAG\n",
    "7. **Response Posting** - Post responses to Reddit (with approval)\n",
    "8. **Analytics Extraction** - Extract engagement metrics and analytics\n",
    "\n",
    "Each cell runs independently and demonstrates the Haystack RAG capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Environment Setup and Configuration\n",
    "import sys\n",
    "import os\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('src')\n",
    "\n",
    "from src.config.settings import settings\n",
    "\n",
    "print(\"üîß Reddit Marketing AI Agent - Haystack RAG Workflow\")\n",
    "print(f\"üìÖ Current Time: {datetime.now()}\")\n",
    "print(f\"üìÅ Data Directory: {settings.DATA_DIR}\")\n",
    "print(f\"ü§ñ Embedding Model: {settings.EMBEDDING_MODEL}\")\n",
    "print(f\"üîç Document Store: {settings.DOCUMENT_STORE_TYPE}\")\n",
    "print(f\"üìä Chunk Size: {settings.CHUNK_SIZE}\")\n",
    "print(f\"üîÑ Chunk Overlap: {settings.CHUNK_OVERLAP}\")\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-haystack-2024\"\n",
    "ORGANIZATION_NAME = \"Demo Organization with Haystack RAG\"\n",
    "\n",
    "# Check API keys\n",
    "required_keys = {\n",
    "    \"OPENAI_API_KEY\": settings.OPENAI_API_KEY,\n",
    "    \"GOOGLE_API_KEY\": settings.GOOGLE_API_KEY\n",
    "}\n",
    "\n",
    "print(\"\\nüîë Required API Keys:\")\n",
    "for key, value in required_keys.items():\n",
    "    status = \"‚úÖ\" if value else \"‚ùå\"\n",
    "    print(f\"   {status} {key}: {'Set' if value else 'Missing'}\")\n",
    "\n",
    "optional_keys = {\n",
    "    \"GROQ_API_KEY\": settings.GROQ_API_KEY,\n",
    "    \"FIRECRAWL_API_KEY\": settings.FIRECRAWL_API_KEY,\n",
    "    \"REDDIT_CLIENT_ID\": settings.REDDIT_CLIENT_ID,\n",
    "    \"REDDIT_CLIENT_SECRET\": settings.REDDIT_CLIENT_SECRET\n",
    "}\n",
    "\n",
    "print(\"\\nüîß Optional API Keys:\")\n",
    "for key, value in optional_keys.items():\n",
    "    status = \"‚úÖ\" if value else \"‚ö†Ô∏è\"\n",
    "    print(f\"   {status} {key}: {'Set' if value else 'Not set'}\")\n",
    "\n",
    "print(\"\\nüöÄ Setup complete! Ready to start workflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Document Ingestion with Multiple Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Document Ingestion - Direct Content\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from src.services.ingestion_service import IngestionService\n",
    "from src.storage.json_storage import JsonStorage\n",
    "from src.storage.vector_storage import VectorStorage\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-haystack-2024\"\n",
    "\n",
    "# Initialize services with Haystack\n",
    "json_storage = JsonStorage()\n",
    "vector_storage = VectorStorage()  # Uses Haystack client internally\n",
    "ingestion_service = IngestionService(json_storage, vector_storage)\n",
    "\n",
    "# Sample content for ingestion\n",
    "python_content = \"\"\"\n",
    "Python Best Practices and Advanced Techniques\n",
    "\n",
    "Python is a versatile programming language that excels in multiple domains:\n",
    "\n",
    "1. Web Development:\n",
    "   - Django: Full-featured web framework with ORM, admin interface, and security features\n",
    "   - Flask: Lightweight and flexible microframework for building web applications\n",
    "   - FastAPI: Modern, fast web framework for building APIs with automatic documentation\n",
    "\n",
    "2. Data Science and Machine Learning:\n",
    "   - NumPy: Fundamental package for scientific computing with powerful array operations\n",
    "   - Pandas: Data manipulation and analysis library with DataFrame structures\n",
    "   - Scikit-learn: Machine learning library with algorithms for classification, regression, clustering\n",
    "   - TensorFlow/PyTorch: Deep learning frameworks for neural networks\n",
    "\n",
    "3. Best Practices:\n",
    "   - Follow PEP 8 style guidelines for consistent code formatting\n",
    "   - Use virtual environments to manage dependencies\n",
    "   - Write comprehensive unit tests with pytest\n",
    "   - Implement proper error handling with try-except blocks\n",
    "   - Use type hints for better code documentation and IDE support\n",
    "   - Apply SOLID principles for maintainable object-oriented design\n",
    "\n",
    "4. Performance Optimization:\n",
    "   - Use list comprehensions instead of loops when appropriate\n",
    "   - Leverage built-in functions like map(), filter(), and reduce()\n",
    "   - Profile code with cProfile to identify bottlenecks\n",
    "   - Consider using NumPy for numerical computations\n",
    "   - Implement caching with functools.lru_cache for expensive operations\n",
    "\n",
    "5. Advanced Topics:\n",
    "   - Decorators for cross-cutting concerns like logging and authentication\n",
    "   - Context managers for resource management\n",
    "   - Generators for memory-efficient iteration\n",
    "   - Asyncio for asynchronous programming\n",
    "   - Metaclasses for advanced class customization\n",
    "\"\"\"\n",
    "\n",
    "# Ingest document using Haystack RAG\n",
    "async def ingest_python_content():\n",
    "    success, message, document_id = await ingestion_service.ingest_document(\n",
    "        content=python_content,\n",
    "        title=\"Python Best Practices and Advanced Techniques\",\n",
    "        organization_id=ORGANIZATION_ID,\n",
    "        chunk_size=800,  # Custom chunk size\n",
    "        chunk_overlap=150  # Custom overlap\n",
    "    )\n",
    "    \n",
    "    print(\"üìÑ Direct Content Ingestion (Haystack RAG)\")\n",
    "    print(f\"   Success: {success}\")\n",
    "    print(f\"   Message: {message}\")\n",
    "    print(f\"   Document ID: {document_id}\")\n",
    "    \n",
    "    if success:\n",
    "        # Get storage stats\n",
    "        stats = vector_storage.get_storage_info(ORGANIZATION_ID)\n",
    "        print(f\"   Storage Stats: {stats}\")\n",
    "    \n",
    "    return document_id\n",
    "\n",
    "# Run the ingestion\n",
    "python_doc_id = await ingest_python_content()\n",
    "print(f\"\\n‚úÖ Python content ingested with Haystack RAG: {python_doc_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Document Ingestion - URL Scraping\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from src.services.ingestion_service import IngestionService\n",
    "from src.storage.json_storage import JsonStorage\n",
    "from src.storage.vector_storage import VectorStorage\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-haystack-2024\"\n",
    "URL_TO_SCRAPE = \"https://docs.python.org/3/tutorial/introduction.html\"\n",
    "\n",
    "# Initialize services\n",
    "json_storage = JsonStorage()\n",
    "vector_storage = VectorStorage()\n",
    "ingestion_service = IngestionService(json_storage, vector_storage)\n",
    "\n",
    "# Ingest from URL using Haystack RAG\n",
    "async def ingest_from_url():\n",
    "    success, message, document_id = await ingestion_service.ingest_document(\n",
    "        content=URL_TO_SCRAPE,\n",
    "        title=\"Python Tutorial Introduction (Official Docs)\",\n",
    "        organization_id=ORGANIZATION_ID,\n",
    "        is_url=True,\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    \n",
    "    print(\"üåê URL Scraping Ingestion (Haystack RAG)\")\n",
    "    print(f\"   URL: {URL_TO_SCRAPE}\")\n",
    "    print(f\"   Success: {success}\")\n",
    "    print(f\"   Message: {message}\")\n",
    "    print(f\"   Document ID: {document_id}\")\n",
    "    \n",
    "    if success:\n",
    "        # Test document retrieval\n",
    "        chunks = vector_storage.get_document_chunks_by_document_id(\n",
    "            org_id=ORGANIZATION_ID,\n",
    "            document_id=document_id\n",
    "        )\n",
    "        print(f\"   Chunks Retrieved: {len(chunks)}\")\n",
    "        if chunks:\n",
    "            print(f\"   First Chunk Preview: {chunks[0]['content'][:100]}...\")\n",
    "    \n",
    "    return document_id\n",
    "\n",
    "# Run URL ingestion\n",
    "url_doc_id = await ingest_from_url()\n",
    "print(f\"\\n‚úÖ URL content ingested with Haystack RAG: {url_doc_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Document Ingestion - Multiple Documents Batch\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from src.services.ingestion_service import IngestionService\n",
    "from src.storage.json_storage import JsonStorage\n",
    "from src.storage.vector_storage import VectorStorage\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-haystack-2024\"\n",
    "\n",
    "# Initialize services\n",
    "json_storage = JsonStorage()\n",
    "vector_storage = VectorStorage()\n",
    "ingestion_service = IngestionService(json_storage, vector_storage)\n",
    "\n",
    "# Multiple documents for batch ingestion\n",
    "documents_to_ingest = [\n",
    "    {\n",
    "        \"title\": \"Machine Learning with Python\",\n",
    "        \"content\": \"\"\"\n",
    "        Machine Learning with Python: A Comprehensive Guide\n",
    "        \n",
    "        Python has become the de facto language for machine learning due to its rich ecosystem:\n",
    "        \n",
    "        1. Core Libraries:\n",
    "           - Scikit-learn: General-purpose ML library with algorithms for classification, regression, clustering\n",
    "           - NumPy: Numerical computing foundation with efficient array operations\n",
    "           - Pandas: Data manipulation and analysis with powerful DataFrame structures\n",
    "           - Matplotlib/Seaborn: Data visualization libraries for creating insightful plots\n",
    "        \n",
    "        2. Deep Learning Frameworks:\n",
    "           - TensorFlow: Google's open-source platform for machine learning\n",
    "           - PyTorch: Facebook's dynamic neural network framework\n",
    "           - Keras: High-level neural networks API running on top of TensorFlow\n",
    "        \n",
    "        3. Specialized Libraries:\n",
    "           - NLTK/spaCy: Natural language processing\n",
    "           - OpenCV: Computer vision and image processing\n",
    "           - XGBoost/LightGBM: Gradient boosting frameworks\n",
    "           - Statsmodels: Statistical modeling and econometrics\n",
    "        \n",
    "        4. ML Pipeline Best Practices:\n",
    "           - Data preprocessing and feature engineering\n",
    "           - Cross-validation for model evaluation\n",
    "           - Hyperparameter tuning with GridSearchCV\n",
    "           - Model persistence with joblib or pickle\n",
    "           - Performance monitoring and model versioning\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Python Web Development Frameworks\",\n",
    "        \"content\": \"\"\"\n",
    "        Python Web Development: Choosing the Right Framework\n",
    "        \n",
    "        Python offers several excellent web frameworks for different use cases:\n",
    "        \n",
    "        1. Django - The Web Framework for Perfectionists:\n",
    "           - Full-featured framework with \"batteries included\" philosophy\n",
    "           - Built-in ORM, admin interface, authentication, and security features\n",
    "           - Perfect for complex, database-driven applications\n",
    "           - Strong community and extensive third-party packages\n",
    "        \n",
    "        2. Flask - Lightweight and Flexible:\n",
    "           - Microframework that gives you control over components\n",
    "           - Minimal core with extensions for additional functionality\n",
    "           - Great for small to medium applications and APIs\n",
    "           - Easy to learn and highly customizable\n",
    "        \n",
    "        3. FastAPI - Modern and Fast:\n",
    "           - High-performance framework for building APIs\n",
    "           - Automatic API documentation with Swagger/OpenAPI\n",
    "           - Built-in support for async/await and type hints\n",
    "           - Excellent for microservices and modern web APIs\n",
    "        \n",
    "        4. Other Notable Frameworks:\n",
    "           - Pyramid: Flexible framework for large applications\n",
    "           - Tornado: Asynchronous networking library\n",
    "           - Bottle: Minimalist WSGI micro web-framework\n",
    "           - Sanic: Async Python web server and framework\n",
    "        \n",
    "        5. Development Best Practices:\n",
    "           - Use virtual environments for dependency management\n",
    "           - Implement proper error handling and logging\n",
    "           - Follow RESTful API design principles\n",
    "           - Use environment variables for configuration\n",
    "           - Implement comprehensive testing strategies\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Python Data Science Ecosystem\",\n",
    "        \"content\": \"\"\"\n",
    "        Python Data Science: Tools and Techniques\n",
    "        \n",
    "        Python's data science ecosystem is unmatched in its breadth and depth:\n",
    "        \n",
    "        1. Data Manipulation and Analysis:\n",
    "           - Pandas: DataFrame operations, data cleaning, and transformation\n",
    "           - NumPy: Numerical computing with efficient array operations\n",
    "           - Dask: Parallel computing for larger-than-memory datasets\n",
    "           - Polars: Fast DataFrame library with lazy evaluation\n",
    "        \n",
    "        2. Visualization Libraries:\n",
    "           - Matplotlib: Comprehensive plotting library with fine-grained control\n",
    "           - Seaborn: Statistical data visualization built on matplotlib\n",
    "           - Plotly: Interactive plots and dashboards\n",
    "           - Bokeh: Interactive visualization for web applications\n",
    "        \n",
    "        3. Statistical Analysis:\n",
    "           - SciPy: Scientific computing with optimization, integration, interpolation\n",
    "           - Statsmodels: Statistical modeling and econometrics\n",
    "           - PyMC: Probabilistic programming for Bayesian analysis\n",
    "        \n",
    "        4. Jupyter Ecosystem:\n",
    "           - Jupyter Notebooks: Interactive computing environment\n",
    "           - JupyterLab: Next-generation notebook interface\n",
    "           - Voila: Turn notebooks into standalone web applications\n",
    "        \n",
    "        5. Data Science Workflow:\n",
    "           - Data collection and ingestion\n",
    "           - Exploratory data analysis (EDA)\n",
    "           - Feature engineering and selection\n",
    "           - Model development and validation\n",
    "           - Results interpretation and communication\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Batch ingest documents\n",
    "async def batch_ingest_documents():\n",
    "    ingested_docs = []\n",
    "    \n",
    "    print(\"üìö Batch Document Ingestion (Haystack RAG)\")\n",
    "    print(f\"   Total Documents: {len(documents_to_ingest)}\")\n",
    "    \n",
    "    for i, doc_data in enumerate(documents_to_ingest, 1):\n",
    "        print(f\"\\n   üìÑ Ingesting Document {i}/{len(documents_to_ingest)}: {doc_data['title']}\")\n",
    "        \n",
    "        success, message, document_id = await ingestion_service.ingest_document(\n",
    "            content=doc_data[\"content\"],\n",
    "            title=doc_data[\"title\"],\n",
    "            organization_id=ORGANIZATION_ID,\n",
    "            chunk_size=900,\n",
    "            chunk_overlap=180\n",
    "        )\n",
    "        \n",
    "        print(f\"      Success: {success}\")\n",
    "        print(f\"      Document ID: {document_id}\")\n",
    "        \n",
    "        if success:\n",
    "            ingested_docs.append(document_id)\n",
    "    \n",
    "    # Get final storage stats\n",
    "    stats = vector_storage.get_storage_info(ORGANIZATION_ID)\n",
    "    print(f\"\\nüìä Final Storage Stats: {stats}\")\n",
    "    \n",
    "    return ingested_docs\n",
    "\n",
    "# Run batch ingestion\n",
    "batch_doc_ids = await batch_ingest_documents()\n",
    "print(f\"\\n‚úÖ Batch ingestion complete! Documents: {len(batch_doc_ids)}\")\n",
    "print(f\"   Document IDs: {batch_doc_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Topic Extraction using Haystack RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Topic Extraction from Documents using Haystack RAG\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from src.services.subreddit_service import SubredditService\n",
    "from src.clients.reddit_client import RedditClient\n",
    "from src.clients.llm_client import LLMClient\n",
    "from src.storage.vector_storage import VectorStorage\n",
    "from src.config.settings import settings\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-haystack-2024\"\n",
    "\n",
    "# Initialize services\n",
    "vector_storage = VectorStorage()\n",
    "llm_client = LLMClient()\n",
    "reddit_client = RedditClient(\n",
    "    client_id=settings.REDDIT_CLIENT_ID or \"dummy_id\",\n",
    "    client_secret=settings.REDDIT_CLIENT_SECRET or \"dummy_secret\"\n",
    ")\n",
    "subreddit_service = SubredditService(reddit_client, llm_client, vector_storage)\n",
    "\n",
    "# Extract topics using Haystack semantic search\n",
    "async def extract_topics_haystack():\n",
    "    print(\"üîç Topic Extraction using Haystack RAG\")\n",
    "    \n",
    "    # Method 1: Extract topics from all documents using semantic search\n",
    "    print(\"\\n   Method 1: Semantic search across all documents\")\n",
    "    success, message, topics = await subreddit_service.extract_topics_from_documents(\n",
    "        organization_id=ORGANIZATION_ID,\n",
    "        query=\"python programming web development machine learning data science\"\n",
    "    )\n",
    "    \n",
    "    print(f\"   Success: {success}\")\n",
    "    print(f\"   Message: {message}\")\n",
    "    if topics:\n",
    "        print(f\"   Topics Found: {len(topics)}\")\n",
    "        for i, topic in enumerate(topics[:15], 1):  # Show first 15 topics\n",
    "            print(f\"      {i}. {topic}\")\n",
    "    \n",
    "    # Method 2: Extract topics from specific documents\n",
    "    print(\"\\n   Method 2: Extract from specific documents\")\n",
    "    \n",
    "    # Get all documents for this organization\n",
    "    from src.storage.json_storage import JsonStorage\n",
    "    json_storage = JsonStorage()\n",
    "    documents = json_storage.filter_items(\"documents.json\", {\"organization_id\": ORGANIZATION_ID})\n",
    "    \n",
    "    if documents:\n",
    "        # Use first 2 documents\n",
    "        doc_ids = [doc[\"id\"] for doc in documents[:2]]\n",
    "        print(f\"   Using documents: {doc_ids}\")\n",
    "        \n",
    "        success2, message2, topics2 = await subreddit_service.extract_topics_from_documents(\n",
    "            organization_id=ORGANIZATION_ID,\n",
    "            document_ids=doc_ids\n",
    "        )\n",
    "        \n",
    "        print(f\"   Success: {success2}\")\n",
    "        print(f\"   Message: {message2}\")\n",
    "        if topics2:\n",
    "            print(f\"   Topics Found: {len(topics2)}\")\n",
    "            for i, topic in enumerate(topics2[:10], 1):  # Show first 10 topics\n",
    "                print(f\"      {i}. {topic}\")\n",
    "    \n",
    "    # Method 3: Test document querying directly\n",
    "    print(\"\\n   Method 3: Direct document querying with Haystack\")\n",
    "    results = vector_storage.query_documents(\n",
    "        org_id=ORGANIZATION_ID,\n",
    "        query=\"machine learning frameworks\",\n",
    "        method=\"semantic\",\n",
    "        top_k=3\n",
    "    )\n",
    "    \n",
    "    print(f\"   Query Results: {len(results)} chunks found\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"      {i}. Score: {result['score']:.3f} | {result['content'][:80]}...\")\n",
    "    \n",
    "    return topics if topics else []\n",
    "\n",
    "# Run topic extraction\n",
    "extracted_topics = await extract_topics_haystack()\n",
    "print(f\"\\n‚úÖ Topic extraction complete using Haystack RAG!\")\n",
    "print(f\"   Total topics extracted: {len(extracted_topics)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Subreddit Discovery and Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Subreddit Discovery and Ranking with Haystack RAG\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from src.services.subreddit_service import SubredditService\n",
    "from src.clients.reddit_client import RedditClient\n",
    "from src.clients.llm_client import LLMClient\n",
    "from src.storage.vector_storage import VectorStorage\n",
    "from src.config.settings import settings\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-haystack-2024\"\n",
    "TOPICS = [\"python\", \"programming\", \"machine learning\", \"web development\", \"data science\"]\n",
    "\n",
    "# Initialize services\n",
    "vector_storage = VectorStorage()\n",
    "llm_client = LLMClient()\n",
    "reddit_client = RedditClient(\n",
    "    client_id=settings.REDDIT_CLIENT_ID or \"dummy_id\",\n",
    "    client_secret=settings.REDDIT_CLIENT_SECRET or \"dummy_secret\"\n",
    ")\n",
    "subreddit_service = SubredditService(reddit_client, llm_client, vector_storage)\n",
    "\n",
    "# Discover and rank subreddits using Haystack RAG\n",
    "async def discover_subreddits_haystack():\n",
    "    print(\"üéØ Subreddit Discovery and Ranking (Haystack RAG)\")\n",
    "    print(f\"   Topics: {TOPICS}\")\n",
    "    print(f\"   Organization: {ORGANIZATION_ID}\")\n",
    "    \n",
    "    # Method 1: With RAG context from documents\n",
    "    print(\"\\n   Method 1: Using Haystack RAG context\")\n",
    "    success, message, subreddits = await subreddit_service.discover_and_rank_subreddits(\n",
    "        topics=TOPICS,\n",
    "        organization_id=ORGANIZATION_ID,\n",
    "        use_rag_context=True  # Enable Haystack RAG\n",
    "    )\n",
    "    \n",
    "    print(f\"   Success: {success}\")\n",
    "    print(f\"   Message: {message}\")\n",
    "    if subreddits:\n",
    "        print(f\"   Subreddits Found: {len(subreddits)}\")\n",
    "        for i, subreddit in enumerate(subreddits, 1):\n",
    "            print(f\"      {i}. r/{subreddit}\")\n",
    "    \n",
    "    # Method 2: Without RAG context (fallback)\n",
    "    print(\"\\n   Method 2: Without RAG context (fallback)\")\n",
    "    success2, message2, subreddits2 = await subreddit_service.discover_and_rank_subreddits(\n",
    "        topics=TOPICS[:3],  # Use fewer topics\n",
    "        organization_id=ORGANIZATION_ID,\n",
    "        use_rag_context=False  # Disable RAG\n",
    "    )\n",
    "    \n",
    "    print(f\"   Success: {success2}\")\n",
    "    print(f\"   Message: {message2}\")\n",
    "    if subreddits2:\n",
    "        print(f\"   Subreddits Found: {len(subreddits2)}\")\n",
    "        for i, subreddit in enumerate(subreddits2[:5], 1):\n",
    "            print(f\"      {i}. r/{subreddit}\")\n",
    "    \n",
    "    # Method 3: Test direct Reddit search\n",
    "    print(\"\\n   Method 3: Direct Reddit API search\")\n",
    "    try:\n",
    "        async with reddit_client:\n",
    "            search_results = await reddit_client.search_subreddits(\"python programming\", limit=5)\n",
    "            print(f\"   Direct Search Results: {len(search_results)}\")\n",
    "            for i, result in enumerate(search_results, 1):\n",
    "                print(f\"      {i}. r/{result['name']} ({result['subscribers']:,} subscribers)\")\n",
    "                print(f\"         {result['description'][:80]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Direct search failed: {str(e)}\")\n",
    "    \n",
    "    return subreddits if subreddits else []\n",
    "\n",
    "# Run subreddit discovery\n",
    "discovered_subreddits = await discover_subreddits_haystack()\n",
    "print(f\"\\n‚úÖ Subreddit discovery complete using Haystack RAG!\")\n",
    "print(f\"   Total subreddits discovered: {len(discovered_subreddits)}\")\n",
    "if discovered_subreddits:\n",
    "    print(f\"   Top 5 subreddits: {discovered_subreddits[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Post Search in Target Subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Post Search in Target Subreddits\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from src.clients.reddit_client import RedditClient\n",
    "from src.config.settings import settings\n",
    "\n",
    "# Configuration\n",
    "TARGET_SUBREDDITS = [\"learnpython\", \"Python\", \"MachineLearning\", \"webdev\", \"datascience\"]\n",
    "SEARCH_QUERIES = [\"beginner help\", \"best practices\", \"tutorial\", \"getting started\", \"advice\"]\n",
    "\n",
    "# Initialize Reddit client\n",
    "reddit_client = RedditClient(\n",
    "    client_id=settings.REDDIT_CLIENT_ID or \"dummy_id\",\n",
    "    client_secret=settings.REDDIT_CLIENT_SECRET or \"dummy_secret\"\n",
    ")\n",
    "\n",
    "# Search for posts in target subreddits\n",
    "async def search_posts_in_subreddits():\n",
    "    print(\"üîç Post Search in Target Subreddits\")\n",
    "    print(f\"   Target Subreddits: {TARGET_SUBREDDITS}\")\n",
    "    print(f\"   Search Queries: {SEARCH_QUERIES}\")\n",
    "    \n",
    "    all_posts = []\n",
    "    \n",
    "    try:\n",
    "        async with reddit_client:\n",
    "            for subreddit in TARGET_SUBREDDITS:\n",
    "                print(f\"\\n   üìã Searching r/{subreddit}\")\n",
    "                \n",
    "                for query in SEARCH_QUERIES[:2]:  # Limit to 2 queries per subreddit\n",
    "                    try:\n",
    "                        posts = await reddit_client.search_subreddit_posts(\n",
    "                            subreddit=subreddit,\n",
    "                            query=query,\n",
    "                            sort=\"new\",\n",
    "                            time_filter=\"week\",\n",
    "                            limit=3  # Limit posts per query\n",
    "                        )\n",
    "                        \n",
    "                        print(f\"      Query '{query}': {len(posts)} posts found\")\n",
    "                        \n",
    "                        for post in posts:\n",
    "                            post_info = {\n",
    "                                \"id\": post[\"id\"],\n",
    "                                \"title\": post[\"title\"],\n",
    "                                \"subreddit\": subreddit,\n",
    "                                \"author\": post[\"author\"],\n",
    "                                \"score\": post[\"score\"],\n",
    "                                \"num_comments\": post[\"num_comments\"],\n",
    "                                \"content\": post[\"selftext\"][:200] + \"...\" if post[\"selftext\"] else \"[No content]\",\n",
    "                                \"permalink\": post[\"permalink\"],\n",
    "                                \"search_query\": query\n",
    "                            }\n",
    "                            all_posts.append(post_info)\n",
    "                            \n",
    "                            print(f\"         - {post['title'][:60]}... (Score: {post['score']}, Comments: {post['num_comments']})\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"      Error searching '{query}' in r/{subreddit}: {str(e)}\")\n",
    "                        continue\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   Reddit client error: {str(e)}\")\n",
    "        # Create mock posts for demonstration\n",
    "        all_posts = [\n",
    "            {\n",
    "                \"id\": \"mock_post_1\",\n",
    "                \"title\": \"Best Python libraries for beginners?\",\n",
    "                \"subreddit\": \"learnpython\",\n",
    "                \"author\": \"python_learner\",\n",
    "                \"score\": 15,\n",
    "                \"num_comments\": 8,\n",
    "                \"content\": \"I'm new to Python and wondering what libraries I should learn first...\",\n",
    "                \"permalink\": \"/r/learnpython/comments/mock_post_1/\",\n",
    "                \"search_query\": \"beginner help\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"mock_post_2\",\n",
    "                \"title\": \"Machine learning project ideas for portfolio\",\n",
    "                \"subreddit\": \"MachineLearning\",\n",
    "                \"author\": \"ml_student\",\n",
    "                \"score\": 23,\n",
    "                \"num_comments\": 12,\n",
    "                \"content\": \"Looking for intermediate ML project ideas to showcase in my portfolio...\",\n",
    "                \"permalink\": \"/r/MachineLearning/comments/mock_post_2/\",\n",
    "                \"search_query\": \"advice\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"mock_post_3\",\n",
    "                \"title\": \"Web development with Python - Django vs Flask?\",\n",
    "                \"subreddit\": \"webdev\",\n",
    "                \"author\": \"web_developer\",\n",
    "                \"score\": 31,\n",
    "                \"num_comments\": 18,\n",
    "                \"content\": \"I'm trying to decide between Django and Flask for my next project...\",\n",
    "                \"permalink\": \"/r/webdev/comments/mock_post_3/\",\n",
    "                \"search_query\": \"best practices\"\n",
    "            }\n",
    "        ]\n",
    "        print(f\"   Using mock posts for demonstration: {len(all_posts)} posts\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nüìä Post Search Summary:\")\n",
    "    print(f\"   Total Posts Found: {len(all_posts)}\")\n",
    "    \n",
    "    # Group by subreddit\n",
    "    by_subreddit = {}\n",
    "    for post in all_posts:\n",
    "        subreddit = post[\"subreddit\"]\n",
    "        if subreddit not in by_subreddit:\n",
    "            by_subreddit[subreddit] = []\n",
    "        by_subreddit[subreddit].append(post)\n",
    "    \n",
    "    for subreddit, posts in by_subreddit.items():\n",
    "        print(f\"   r/{subreddit}: {len(posts)} posts\")\n",
    "    \n",
    "    # Show top posts by score\n",
    "    top_posts = sorted(all_posts, key=lambda x: x[\"score\"], reverse=True)[:3]\n",
    "    print(f\"\\nüèÜ Top Posts by Score:\")\n",
    "    for i, post in enumerate(top_posts, 1):\n",
    "        print(f\"   {i}. r/{post['subreddit']}: {post['title'][:50]}... (Score: {post['score']})\")\n",
    "    \n",
    "    return all_posts\n",
    "\n",
    "# Run post search\n",
    "found_posts = await search_posts_in_subreddits()\n",
    "print(f\"\\n‚úÖ Post search complete! Found {len(found_posts)} posts across target subreddits.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Post Analysis with Haystack RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Post Analysis with Haystack RAG Integration\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from src.services.posting_service import PostingService\n",
    "from src.clients.reddit_client import RedditClient\n",
    "from src.clients.llm_client import LLMClient\n",
    "from src.storage.vector_storage import VectorStorage\n",
    "from src.storage.json_storage import JsonStorage\n",
    "from src.config.settings import settings\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-haystack-2024\"\n",
    "\n",
    "# Initialize services\n",
    "vector_storage = VectorStorage()\n",
    "json_storage = JsonStorage()\n",
    "llm_client = LLMClient()\n",
    "reddit_client = RedditClient(\n",
    "    client_id=settings.REDDIT_CLIENT_ID or \"dummy_id\",\n",
    "    client_secret=settings.REDDIT_CLIENT_SECRET or \"dummy_secret\"\n",
    ")\n",
    "posting_service = PostingService(reddit_client, llm_client, vector_storage, json_storage)\n",
    "\n",
    "# Mock post data for analysis (since we might not have real Reddit access)\n",
    "mock_posts = [\n",
    "    {\n",
    "        \"id\": \"analysis_post_1\",\n",
    "        \"title\": \"Best Python libraries for data science beginners?\",\n",
    "        \"content\": \"I'm just starting with data science and Python. What libraries should I learn first? I've heard about pandas and numpy but not sure where to start. Any recommendations for learning resources?\",\n",
    "        \"author\": \"data_newbie\",\n",
    "        \"subreddit\": \"datascience\",\n",
    "        \"score\": 25,\n",
    "        \"num_comments\": 15,\n",
    "        \"created_utc\": 1703123456.0,\n",
    "        \"permalink\": \"/r/datascience/comments/analysis_post_1/\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"analysis_post_2\",\n",
    "        \"title\": \"Django vs Flask for my first web project?\",\n",
    "        \"content\": \"I want to build a web application for my portfolio. Should I use Django or Flask? I'm comfortable with Python basics but new to web development. The project will be a simple blog with user authentication.\",\n",
    "        \"author\": \"aspiring_dev\",\n",
    "        \"subreddit\": \"webdev\",\n",
    "        \"score\": 18,\n",
    "        \"num_comments\": 22,\n",
    "        \"created_utc\": 1703109876.0,\n",
    "        \"permalink\": \"/r/webdev/comments/analysis_post_2/\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"analysis_post_3\",\n",
    "        \"title\": \"Machine learning model deployment best practices?\",\n",
    "        \"content\": \"I've trained a scikit-learn model and want to deploy it to production. What are the best practices for model deployment? Should I use Flask API, FastAPI, or something else? Also concerned about model versioning and monitoring.\",\n",
    "        \"author\": \"ml_engineer\",\n",
    "        \"subreddit\": \"MachineLearning\",\n",
    "        \"score\": 42,\n",
    "        \"num_comments\": 31,\n",
    "        \"created_utc\": 1703098765.0,\n",
    "        \"permalink\": \"/r/MachineLearning/comments/analysis_post_3/\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Analyze posts using Haystack RAG\n",
    "async def analyze_posts_with_haystack():\n",
    "    print(\"üî¨ Post Analysis with Haystack RAG Integration\")\n",
    "    print(f\"   Organization: {ORGANIZATION_ID}\")\n",
    "    print(f\"   Posts to Analyze: {len(mock_posts)}\")\n",
    "    \n",
    "    analysis_results = []\n",
    "    \n",
    "    for i, post in enumerate(mock_posts, 1):\n",
    "        print(f\"\\n   üìÑ Analyzing Post {i}/{len(mock_posts)}\")\n",
    "        print(f\"      Title: {post['title']}\")\n",
    "        print(f\"      Subreddit: r/{post['subreddit']}\")\n",
    "        print(f\"      Score: {post['score']}, Comments: {post['num_comments']}\")\n",
    "        \n",
    "        try:\n",
    "            # Use Haystack RAG for context-aware analysis\n",
    "            success, message, analysis_data = await posting_service.analyze_and_generate_response(\n",
    "                post_id=post[\"id\"],\n",
    "                organization_id=ORGANIZATION_ID,\n",
    "                tone=\"helpful\"\n",
    "            )\n",
    "            \n",
    "            print(f\"      Analysis Success: {success}\")\n",
    "            print(f\"      Message: {message}\")\n",
    "            \n",
    "            if success and analysis_data:\n",
    "                print(f\"      RAG Method: {analysis_data.get('rag_method', 'N/A')}\")\n",
    "                print(f\"      Context Chunks Used: {analysis_data.get('context_chunks_used', 0)}\")\n",
    "                print(f\"      Response Type: {analysis_data.get('target', {}).get('response_type', 'N/A')}\")\n",
    "                print(f\"      Confidence: {analysis_data.get('response', {}).get('confidence', 0):.2f}\")\n",
    "                \n",
    "                # Show response preview\n",
    "                response_content = analysis_data.get('response', {}).get('content', '')\n",
    "                if response_content:\n",
    "                    print(f\"      Response Preview: {response_content[:100]}...\")\n",
    "                \n",
    "                analysis_results.append({\n",
    "                    \"post_id\": post[\"id\"],\n",
    "                    \"post_title\": post[\"title\"],\n",
    "                    \"analysis_success\": True,\n",
    "                    \"analysis_data\": analysis_data\n",
    "                })\n",
    "            else:\n",
    "                print(f\"      Analysis failed: {message}\")\n",
    "                analysis_results.append({\n",
    "                    \"post_id\": post[\"id\"],\n",
    "                    \"post_title\": post[\"title\"],\n",
    "                    \"analysis_success\": False,\n",
    "                    \"error\": message\n",
    "                })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"      Error during analysis: {str(e)}\")\n",
    "            \n",
    "            # Fallback: Manual analysis using Haystack directly\n",
    "            print(f\"      Performing fallback analysis...\")\n",
    "            \n",
    "            # Get relevant context using Haystack\n",
    "            search_text = f\"{post['title']} {post['content']}\"\n",
    "            context_results = vector_storage.query_documents(\n",
    "                org_id=ORGANIZATION_ID,\n",
    "                query=search_text,\n",
    "                method=\"semantic\",\n",
    "                top_k=3\n",
    "            )\n",
    "            \n",
    "            print(f\"      Haystack Context Results: {len(context_results)} chunks\")\n",
    "            if context_results:\n",
    "                for j, result in enumerate(context_results, 1):\n",
    "                    print(f\"         {j}. Score: {result['score']:.3f} | {result['content'][:60]}...\")\n",
    "            \n",
    "            analysis_results.append({\n",
    "                \"post_id\": post[\"id\"],\n",
    "                \"post_title\": post[\"title\"],\n",
    "                \"analysis_success\": False,\n",
    "                \"fallback_context_chunks\": len(context_results),\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    \n",
    "    # Summary\n",
    "    successful_analyses = [r for r in analysis_results if r[\"analysis_success\"]]\n",
    "    print(f\"\\nüìä Analysis Summary:\")\n",
    "    print(f\"   Total Posts Analyzed: {len(analysis_results)}\")\n",
    "    print(f\"   Successful Analyses: {len(successful_analyses)}\")\n",
    "    print(f\"   Failed Analyses: {len(analysis_results) - len(successful_analyses)}\")\n",
    "    \n",
    "    if successful_analyses:\n",
    "        print(f\"\\nüéØ Successful Analysis Details:\")\n",
    "        for result in successful_analyses:\n",
    "            analysis_data = result[\"analysis_data\"]\n",
    "            confidence = analysis_data.get('response', {}).get('confidence', 0)\n",
    "            print(f\"   - {result['post_title'][:50]}... (Confidence: {confidence:.2f})\")\n",
    "    \n",
    "    return analysis_results\n",
    "\n",
    "# Run post analysis\n",
    "analysis_results = await analyze_posts_with_haystack()\n",
    "print(f\"\\n‚úÖ Post analysis complete using Haystack RAG!\")\n",
    "print(f\"   Results: {len(analysis_results)} posts analyzed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Response Generation with Haystack RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Response Generation with Haystack RAG Context\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from src.services.posting_service import PostingService\n",
    "from src.clients.reddit_client import RedditClient\n",
    "from src.clients.llm_client import LLMClient\n",
    "from src.storage.vector_storage import VectorStorage\n",
    "from src.storage.json_storage import JsonStorage\n",
    "from src.config.settings import settings\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-haystack-2024\"\n",
    "\n",
    "# Initialize services\n",
    "vector_storage = VectorStorage()\n",
    "json_storage = JsonStorage()\n",
    "llm_client = LLMClient()\n",
    "reddit_client = RedditClient(\n",
    "    client_id=settings.REDDIT_CLIENT_ID or \"dummy_id\",\n",
    "    client_secret=settings.REDDIT_CLIENT_SECRET or \"dummy_secret\"\n",
    ")\n",
    "posting_service = PostingService(reddit_client, llm_client, vector_storage, json_storage)\n",
    "\n",
    "# Sample posts for response generation\n",
    "sample_posts = [\n",
    "    {\n",
    "        \"id\": \"response_post_1\",\n",
    "        \"title\": \"What's the best way to learn Python for data science?\",\n",
    "        \"content\": \"I'm a complete beginner to programming but really interested in data science. Should I learn Python first or jump straight into data science libraries? What's the most efficient learning path?\",\n",
    "        \"author\": \"curious_learner\",\n",
    "        \"subreddit\": \"datascience\",\n",
    "        \"comments\": [\n",
    "            {\"author\": \"data_expert\", \"body\": \"Start with Python basics first, then move to pandas and numpy.\"},\n",
    "            {\"author\": \"ml_practitioner\", \"body\": \"I'd recommend doing some projects while learning the basics.\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"response_post_2\",\n",
    "        \"title\": \"Flask vs Django for a beginner web developer?\",\n",
    "        \"content\": \"I want to build my first web application. I know Python basics but I'm torn between Flask and Django. The app will be a simple portfolio site with a blog. Which framework should I choose?\",\n",
    "        \"author\": \"web_newbie\",\n",
    "        \"subreddit\": \"webdev\",\n",
    "        \"comments\": [\n",
    "            {\"author\": \"senior_dev\", \"body\": \"For a simple portfolio, Flask might be easier to start with.\"},\n",
    "            {\"author\": \"django_fan\", \"body\": \"Django has more built-in features that you'll appreciate later.\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"response_post_3\",\n",
    "        \"title\": \"How to deploy machine learning models in production?\",\n",
    "        \"content\": \"I've built a scikit-learn model that works well in Jupyter notebooks. Now I need to deploy it for real users. What are the best practices for ML model deployment? Should I use Flask, FastAPI, or something else?\",\n",
    "        \"author\": \"ml_student\",\n",
    "        \"subreddit\": \"MachineLearning\",\n",
    "        \"comments\": [\n",
    "            {\"author\": \"devops_engineer\", \"body\": \"FastAPI is great for ML APIs with automatic documentation.\"},\n",
    "            {\"author\": \"cloud_architect\", \"body\": \"Consider using cloud services like AWS SageMaker or Google AI Platform.\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Generate responses using Haystack RAG\n",
    "async def generate_responses_with_haystack():\n",
    "    print(\"ü§ñ Response Generation with Haystack RAG\")\n",
    "    print(f\"   Organization: {ORGANIZATION_ID}\")\n",
    "    print(f\"   Posts for Response Generation: {len(sample_posts)}\")\n",
    "    \n",
    "    generated_responses = []\n",
    "    \n",
    "    for i, post in enumerate(sample_posts, 1):\n",
    "        print(f\"\\n   üìù Generating Response {i}/{len(sample_posts)}\")\n",
    "        print(f\"      Post: {post['title']}\")\n",
    "        print(f\"      Subreddit: r/{post['subreddit']}\")\n",
    "        \n",
    "        try:\n",
    "            # Method 1: Full analysis and response generation\n",
    "            print(f\"      Method 1: Full Haystack RAG analysis\")\n",
    "            success, message, response_data = await posting_service.analyze_and_generate_response(\n",
    "                post_id=post[\"id\"],\n",
    "                organization_id=ORGANIZATION_ID,\n",
    "                tone=\"helpful\"\n",
    "            )\n",
    "            \n",
    "            if success and response_data:\n",
    "                print(f\"      ‚úÖ Response generated successfully\")\n",
    "                print(f\"      RAG Method: {response_data.get('rag_method', 'N/A')}\")\n",
    "                print(f\"      Context Chunks: {response_data.get('context_chunks_used', 0)}\")\n",
    "                print(f\"      Target Type: {response_data.get('target', {}).get('response_type', 'N/A')}\")\n",
    "                print(f\"      Confidence: {response_data.get('response', {}).get('confidence', 0):.2f}\")\n",
    "                \n",
    "                response_content = response_data.get('response', {}).get('content', '')\n",
    "                print(f\"      Response Length: {len(response_content)} characters\")\n",
    "                print(f\"      Response Preview: {response_content[:150]}...\")\n",
    "                \n",
    "                generated_responses.append({\n",
    "                    \"post_id\": post[\"id\"],\n",
    "                    \"post_title\": post[\"title\"],\n",
    "                    \"method\": \"full_haystack_rag\",\n",
    "                    \"success\": True,\n",
    "                    \"response_data\": response_data,\n",
    "                    \"response_content\": response_content\n",
    "                })\n",
    "            else:\n",
    "                print(f\"      ‚ùå Full analysis failed: {message}\")\n",
    "                \n",
    "                # Method 2: Fallback - Direct context retrieval and LLM generation\n",
    "                print(f\"      Method 2: Fallback with direct Haystack query\")\n",
    "                \n",
    "                # Get relevant context using Haystack\n",
    "                search_query = f\"{post['title']} {post['content']}\"\n",
    "                context_results = vector_storage.query_documents(\n",
    "                    org_id=ORGANIZATION_ID,\n",
    "                    query=search_query,\n",
    "                    method=\"semantic\",\n",
    "                    top_k=3\n",
    "                )\n",
    "                \n",
    "                if context_results:\n",
    "                    context_content = \"\\n\\n\".join([result[\"content\"] for result in context_results])\n",
    "                    \n",
    "                    # Generate response using LLM with context\n",
    "                    prompt = f\"\"\"\n",
    "                    Based on the following context about Python and programming, provide a helpful response to this Reddit post:\n",
    "                    \n",
    "                    Context:\n",
    "                    {context_content[:1000]}...\n",
    "                    \n",
    "                    Post Title: {post['title']}\n",
    "                    Post Content: {post['content']}\n",
    "                    \n",
    "                    Generate a helpful, informative response that adds value to the discussion.\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "                    llm_response = await llm_client.generate_chat_completion(\n",
    "                        messages=messages,\n",
    "                        temperature=0.7\n",
    "                    )\n",
    "                    \n",
    "                    if \"error\" not in llm_response:\n",
    "                        fallback_content = llm_response.get(\"content\", \"\")\n",
    "                        print(f\"      ‚úÖ Fallback response generated\")\n",
    "                        print(f\"      Context Chunks: {len(context_results)}\")\n",
    "                        print(f\"      Response Length: {len(fallback_content)} characters\")\n",
    "                        print(f\"      Response Preview: {fallback_content[:150]}...\")\n",
    "                        \n",
    "                        generated_responses.append({\n",
    "                            \"post_id\": post[\"id\"],\n",
    "                            \"post_title\": post[\"title\"],\n",
    "                            \"method\": \"fallback_haystack_context\",\n",
    "                            \"success\": True,\n",
    "                            \"context_chunks_used\": len(context_results),\n",
    "                            \"response_content\": fallback_content\n",
    "                        })\n",
    "                    else:\n",
    "                        print(f\"      ‚ùå Fallback LLM generation failed: {llm_response.get('error')}\")\n",
    "                        generated_responses.append({\n",
    "                            \"post_id\": post[\"id\"],\n",
    "                            \"post_title\": post[\"title\"],\n",
    "                            \"method\": \"failed\",\n",
    "                            \"success\": False,\n",
    "                            \"error\": llm_response.get('error')\n",
    "                        })\n",
    "                else:\n",
    "                    print(f\"      ‚ùå No relevant context found in documents\")\n",
    "                    generated_responses.append({\n",
    "                        \"post_id\": post[\"id\"],\n",
    "                        \"post_title\": post[\"title\"],\n",
    "                        \"method\": \"no_context\",\n",
    "                        \"success\": False,\n",
    "                        \"error\": \"No relevant context found\"\n",
    "                    })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"      ‚ùå Error generating response: {str(e)}\")\n",
    "            generated_responses.append({\n",
    "                \"post_id\": post[\"id\"],\n",
    "                \"post_title\": post[\"title\"],\n",
    "                \"method\": \"error\",\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    \n",
    "    # Summary\n",
    "    successful_responses = [r for r in generated_responses if r[\"success\"]]\n",
    "    print(f\"\\nüìä Response Generation Summary:\")\n",
    "    print(f\"   Total Posts Processed: {len(generated_responses)}\")\n",
    "    print(f\"   Successful Responses: {len(successful_responses)}\")\n",
    "    print(f\"   Failed Responses: {len(generated_responses) - len(successful_responses)}\")\n",
    "    \n",
    "    # Method breakdown\n",
    "    method_counts = {}\n",
    "    for response in generated_responses:\n",
    "        method = response[\"method\"]\n",
    "        method_counts[method] = method_counts.get(method, 0) + 1\n",
    "    \n",
    "    print(f\"\\nüîß Method Breakdown:\")\n",
    "    for method, count in method_counts.items():\n",
    "        print(f\"   {method}: {count} responses\")\n",
    "    \n",
    "    if successful_responses:\n",
    "        print(f\"\\n‚ú® Sample Generated Responses:\")\n",
    "        for i, response in enumerate(successful_responses[:2], 1):\n",
    "            print(f\"   {i}. {response['post_title'][:40]}...\")\n",
    "            print(f\"      Method: {response['method']}\")\n",
    "            content = response.get('response_content', '')\n",
    "            print(f\"      Content: {content[:100]}...\")\n",
    "    \n",
    "    return generated_responses\n",
    "\n",
    "# Run response generation\n",
    "response_results = await generate_responses_with_haystack()\n",
    "print(f\"\\n‚úÖ Response generation complete using Haystack RAG!\")\n",
    "print(f\"   Generated responses: {len([r for r in response_results if r['success']])} successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Response Posting (with Approval Workflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Response Posting with Approval Workflow\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from src.services.posting_service import PostingService\n",
    "from src.clients.reddit_client import RedditClient\n",
    "from src.clients.llm_client import LLMClient\n",
    "from src.storage.vector_storage import VectorStorage\n",
    "from src.storage.json_storage import JsonStorage\n",
    "from src.config.settings import settings\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-haystack-2024\"\n",
    "\n",
    "# Initialize services\n",
    "vector_storage = VectorStorage()\n",
    "json_storage = JsonStorage()\n",
    "llm_client = LLMClient()\n",
    "reddit_client = RedditClient(\n",
    "    client_id=settings.REDDIT_CLIENT_ID or \"dummy_id\",\n",
    "    client_secret=settings.REDDIT_CLIENT_SECRET or \"dummy_secret\"\n",
    ")\n",
    "posting_service = PostingService(reddit_client, llm_client, vector_storage, json_storage)\n",
    "\n",
    "# Sample approved responses for posting\n",
    "approved_responses = [\n",
    "    {\n",
    "        \"id\": \"approved_response_1\",\n",
    "        \"target_id\": \"sample_post_1\",\n",
    "        \"response_type\": \"post_comment\",\n",
    "        \"content\": \"\"\"\n",
    "Great question! For data science with Python, I'd recommend this learning path:\n",
    "\n",
    "1. **Python Basics First**: Start with core Python concepts - variables, functions, control structures, and object-oriented programming. This foundation is crucial.\n",
    "\n",
    "2. **Essential Libraries**:\n",
    "   - **NumPy**: Learn array operations and numerical computing fundamentals\n",
    "   - **Pandas**: Master data manipulation, cleaning, and analysis with DataFrames\n",
    "   - **Matplotlib/Seaborn**: Understand data visualization techniques\n",
    "\n",
    "3. **Machine Learning**: Once comfortable with the above, move to:\n",
    "   - **Scikit-learn**: Start with classification, regression, and clustering algorithms\n",
    "   - **Jupyter Notebooks**: Essential for interactive data analysis\n",
    "\n",
    "4. **Practice Projects**: Apply your knowledge with real datasets from Kaggle or UCI ML Repository.\n",
    "\n",
    "The key is to balance theory with hands-on practice. Don't rush - solid fundamentals will serve you well as you advance to more complex topics like deep learning with TensorFlow or PyTorch.\n",
    "\n",
    "Good luck with your data science journey!\n",
    "        \"\"\".strip(),\n",
    "        \"post_title\": \"What's the best way to learn Python for data science?\",\n",
    "        \"subreddit\": \"datascience\",\n",
    "        \"confidence\": 0.85\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"approved_response_2\",\n",
    "        \"target_id\": \"sample_post_2\",\n",
    "        \"response_type\": \"post_comment\",\n",
    "        \"content\": \"\"\"\n",
    "For a beginner building a portfolio site with a blog, I'd actually recommend **Flask** for several reasons:\n",
    "\n",
    "**Why Flask for your first project:**\n",
    "- **Simplicity**: Minimal setup, easier to understand what each piece does\n",
    "- **Learning**: You'll understand web development concepts better when building from scratch\n",
    "- **Flexibility**: Perfect for a simple portfolio + blog combination\n",
    "- **Gradual complexity**: You can add features as you learn\n",
    "\n",
    "**Suggested Flask stack for your project:**\n",
    "- Flask + SQLAlchemy (database)\n",
    "- Flask-Login (user authentication)\n",
    "- Jinja2 templates (comes with Flask)\n",
    "- Bootstrap for responsive design\n",
    "\n",
    "**When to consider Django:**\n",
    "Django would be better if you were building a more complex application with multiple apps, admin interface needs, or complex user management from the start.\n",
    "\n",
    "Start with Flask, get comfortable with web development concepts, then you can always migrate to Django later or use it for your next project. The Python web development skills transfer between frameworks.\n",
    "\n",
    "Happy coding!\n",
    "        \"\"\".strip(),\n",
    "        \"post_title\": \"Flask vs Django for a beginner web developer?\",\n",
    "        \"subreddit\": \"webdev\",\n",
    "        \"confidence\": 0.92\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"approved_response_3\",\n",
    "        \"target_id\": \"sample_post_3\",\n",
    "        \"response_type\": \"post_comment\",\n",
    "        \"content\": \"\"\"\n",
    "Excellent question! Moving from Jupyter notebooks to production is a common challenge. Here's a comprehensive approach:\n",
    "\n",
    "**API Framework Choice:**\n",
    "- **FastAPI**: My top recommendation for ML APIs. Automatic documentation, type hints, async support, and excellent performance\n",
    "- **Flask**: Good for simpler deployments, lots of resources available\n",
    "\n",
    "**Deployment Best Practices:**\n",
    "\n",
    "1. **Model Serialization**: Use `joblib` or `pickle` to save your trained model\n",
    "2. **API Structure**: Create endpoints for prediction, health checks, and model info\n",
    "3. **Input Validation**: Use Pydantic models (especially with FastAPI) to validate input data\n",
    "4. **Error Handling**: Implement proper exception handling for invalid inputs\n",
    "\n",
    "**Production Considerations:**\n",
    "- **Containerization**: Use Docker for consistent environments\n",
    "- **Model Versioning**: Track model versions and enable rollbacks\n",
    "- **Monitoring**: Log predictions, response times, and model performance\n",
    "- **Scaling**: Consider using Gunicorn/Uvicorn for production servers\n",
    "\n",
    "**Quick FastAPI Example:**\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "import joblib\n",
    "\n",
    "app = FastAPI()\n",
    "model = joblib.load('model.pkl')\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(data: InputModel):\n",
    "    prediction = model.predict([data.features])\n",
    "    return {\"prediction\": prediction[0]}\n",
    "```\n",
    "\n",
    "Start simple, then add complexity as needed!\n",
    "        \"\"\".strip(),\n",
    "        \"post_title\": \"How to deploy machine learning models in production?\",\n",
    "        \"subreddit\": \"MachineLearning\",\n",
    "        \"confidence\": 0.88\n",
    "    }\n",
    "]\n",
    "\n",
    "# Simulate response posting with approval workflow\n",
    "async def post_approved_responses():\n",
    "    print(\"üì§ Response Posting with Approval Workflow\")\n",
    "    print(f\"   Approved Responses: {len(approved_responses)}\")\n",
    "    print(f\"   Organization: {ORGANIZATION_ID}\")\n",
    "    \n",
    "    posting_results = []\n",
    "    \n",
    "    for i, response in enumerate(approved_responses, 1):\n",
    "        print(f\"\\n   üìù Processing Response {i}/{len(approved_responses)}\")\n",
    "        print(f\"      Target Post: {response['post_title'][:50]}...\")\n",
    "        print(f\"      Subreddit: r/{response['subreddit']}\")\n",
    "        print(f\"      Response Type: {response['response_type']}\")\n",
    "        print(f\"      Confidence: {response['confidence']:.2f}\")\n",
    "        print(f\"      Content Length: {len(response['content'])} characters\")\n",
    "        \n",
    "        # Show approval workflow\n",
    "        print(f\"\\n      üîç Approval Workflow:\")\n",
    "        print(f\"         ‚úÖ Content reviewed and approved\")\n",
    "        print(f\"         ‚úÖ Tone appropriate for subreddit\")\n",
    "        print(f\"         ‚úÖ Adds value to discussion\")\n",
    "        print(f\"         ‚úÖ No promotional content detected\")\n",
    "        print(f\"         ‚úÖ Confidence threshold met ({response['confidence']:.2f} > 0.7)\")\n",
    "        \n",
    "        # Simulate posting (since we might not have real Reddit credentials)\n",
    "        try:\n",
    "            # In a real scenario, this would post to Reddit\n",
    "            # For demo purposes, we'll simulate the posting process\n",
    "            \n",
    "            if settings.REDDIT_CLIENT_ID and settings.REDDIT_CLIENT_SECRET:\n",
    "                print(f\"      üöÄ Attempting to post to Reddit...\")\n",
    "                \n",
    "                success, message, result = await posting_service.post_approved_response(\n",
    "                    target_id=response[\"target_id\"],\n",
    "                    response_type=response[\"response_type\"],\n",
    "                    response_content=response[\"content\"]\n",
    "                )\n",
    "                \n",
    "                if success:\n",
    "                    print(f\"      ‚úÖ Successfully posted to Reddit\")\n",
    "                    print(f\"      Reddit Comment ID: {result.get('id', 'N/A')}\")\n",
    "                    print(f\"      Permalink: {result.get('permalink', 'N/A')}\")\n",
    "                    \n",
    "                    posting_results.append({\n",
    "                        \"response_id\": response[\"id\"],\n",
    "                        \"success\": True,\n",
    "                        \"reddit_comment_id\": result.get('id'),\n",
    "                        \"permalink\": result.get('permalink'),\n",
    "                        \"posted_at\": datetime.now().isoformat()\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"      ‚ùå Failed to post: {message}\")\n",
    "                    posting_results.append({\n",
    "                        \"response_id\": response[\"id\"],\n",
    "                        \"success\": False,\n",
    "                        \"error\": message\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"      üîß Simulating Reddit posting (no credentials provided)\")\n",
    "                \n",
    "                # Simulate successful posting\n",
    "                mock_comment_id = f\"mock_comment_{i}\"\n",
    "                mock_permalink = f\"/r/{response['subreddit']}/comments/{response['target_id']}/comment/{mock_comment_id}/\"\n",
    "                \n",
    "                print(f\"      ‚úÖ Simulated successful posting\")\n",
    "                print(f\"      Mock Comment ID: {mock_comment_id}\")\n",
    "                print(f\"      Mock Permalink: {mock_permalink}\")\n",
    "                \n",
    "                # Log the simulated posting\n",
    "                log_entry = {\n",
    "                    \"id\": f\"log_{response['id']}\",\n",
    "                    \"target_id\": response[\"target_id\"],\n",
    "                    \"response_type\": response[\"response_type\"],\n",
    "                    \"response_content\": response[\"content\"],\n",
    "                    \"posted_at\": datetime.now().timestamp(),\n",
    "                    \"reddit_response\": {\n",
    "                        \"id\": mock_comment_id,\n",
    "                        \"permalink\": mock_permalink\n",
    "                    },\n",
    "                    \"success\": True,\n",
    "                    \"simulated\": True,\n",
    "                    \"rag_enabled\": True,\n",
    "                    \"confidence\": response[\"confidence\"]\n",
    "                }\n",
    "                \n",
    "                json_storage.update_item(\"posted_responses.json\", log_entry)\n",
    "                \n",
    "                posting_results.append({\n",
    "                    \"response_id\": response[\"id\"],\n",
    "                    \"success\": True,\n",
    "                    \"reddit_comment_id\": mock_comment_id,\n",
    "                    \"permalink\": mock_permalink,\n",
    "                    \"posted_at\": datetime.now().isoformat(),\n",
    "                    \"simulated\": True\n",
    "                })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"      ‚ùå Error during posting: {str(e)}\")\n",
    "            posting_results.append({\n",
    "                \"response_id\": response[\"id\"],\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    \n",
    "    # Summary\n",
    "    successful_posts = [r for r in posting_results if r[\"success\"]]\n",
    "    print(f\"\\nüìä Posting Summary:\")\n",
    "    print(f\"   Total Responses Processed: {len(posting_results)}\")\n",
    "    print(f\"   Successfully Posted: {len(successful_posts)}\")\n",
    "    print(f\"   Failed Posts: {len(posting_results) - len(successful_posts)}\")\n",
    "    \n",
    "    if successful_posts:\n",
    "        print(f\"\\n‚úÖ Successfully Posted Responses:\")\n",
    "        for result in successful_posts:\n",
    "            status = \"(Simulated)\" if result.get(\"simulated\") else \"(Real)\"\n",
    "            print(f\"   - {result['response_id']}: {result['reddit_comment_id']} {status}\")\n",
    "    \n",
    "    # Show posting log\n",
    "    print(f\"\\nüìã Posting Log:\")\n",
    "    posted_responses_log = json_storage.load_data(\"posted_responses.json\")\n",
    "    print(f\"   Total logged responses: {len(posted_responses_log)}\")\n",
    "    \n",
    "    return posting_results\n",
    "\n",
    "# Run response posting\n",
    "posting_results = await post_approved_responses()\n",
    "print(f\"\\n‚úÖ Response posting workflow complete!\")\n",
    "print(f\"   Posted responses: {len([r for r in posting_results if r['success']])} successful\")\n",
    "print(f\"   All responses logged for analytics tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analytics Extraction and Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Analytics Extraction and Comprehensive Reporting\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from src.services.analytics_service import AnalyticsService\n",
    "from src.clients.reddit_client import RedditClient\n",
    "from src.storage.json_storage import JsonStorage\n",
    "from src.storage.vector_storage import VectorStorage\n",
    "from src.config.settings import settings\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import statistics\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-haystack-2024\"\n",
    "\n",
    "# Initialize services\n",
    "json_storage = JsonStorage()\n",
    "vector_storage = VectorStorage()\n",
    "reddit_client = RedditClient(\n",
    "    client_id=settings.REDDIT_CLIENT_ID or \"dummy_id\",\n",
    "    client_secret=settings.REDDIT_CLIENT_SECRET or \"dummy_secret\"\n",
    ")\n",
    "analytics_service = AnalyticsService(json_storage, reddit_client)\n",
    "\n",
    "# Comprehensive analytics extraction\n",
    "async def extract_comprehensive_analytics():\n",
    "    print(\"üìä Comprehensive Analytics Extraction\")\n",
    "    print(f\"   Organization: {ORGANIZATION_ID}\")\n",
    "    print(f\"   Timestamp: {datetime.now()}\")\n",
    "    \n",
    "    analytics_report = {}\n",
    "    \n",
    "    # 1. Document Analytics\n",
    "    print(f\"\\n   üìö Document Analytics\")\n",
    "    try:\n",
    "        # Get document statistics\n",
    "        documents = json_storage.filter_items(\"documents.json\", {\"organization_id\": ORGANIZATION_ID})\n",
    "        organizations = json_storage.filter_items(\"organizations.json\", {\"id\": ORGANIZATION_ID})\n",
    "        \n",
    "        total_documents = len(documents)\n",
    "        total_content_length = sum(doc.get(\"content_length\", 0) for doc in documents)\n",
    "        total_chunks = sum(doc.get(\"chunk_count\", 0) for doc in documents)\n",
    "        \n",
    "        # Get storage statistics from Haystack\n",
    "        storage_stats = vector_storage.get_storage_info(ORGANIZATION_ID)\n",
    "        \n",
    "        document_analytics = {\n",
    "            \"total_documents\": total_documents,\n",
    "            \"total_content_length\": total_content_length,\n",
    "            \"total_chunks\": total_chunks,\n",
    "            \"average_content_length\": total_content_length / total_documents if total_documents > 0 else 0,\n",
    "            \"average_chunks_per_document\": total_chunks / total_documents if total_documents > 0 else 0,\n",
    "            \"storage_backend\": \"haystack_chroma\",\n",
    "            \"storage_stats\": storage_stats\n",
    "        }\n",
    "        \n",
    "        analytics_report[\"document_analytics\"] = document_analytics\n",
    "        \n",
    "        print(f\"      Documents: {total_documents}\")\n",
    "        print(f\"      Total Content: {total_content_length:,} characters\")\n",
    "        print(f\"      Total Chunks: {total_chunks}\")\n",
    "        print(f\"      Storage Status: {storage_stats.get('status', 'unknown')}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      Error in document analytics: {str(e)}\")\n",
    "        analytics_report[\"document_analytics\"] = {\"error\": str(e)}\n",
    "    \n",
    "    # 2. Response Analytics\n",
    "    print(f\"\\n   üí¨ Response Analytics\")\n",
    "    try:\n",
    "        # Get engagement report\n",
    "        engagement_report = await analytics_service.get_engagement_report(ORGANIZATION_ID)\n",
    "        \n",
    "        # Get posting history\n",
    "        posting_history = analytics_service.get_posting_history(ORGANIZATION_ID, limit=100)\n",
    "        \n",
    "        response_analytics = {\n",
    "            \"engagement_report\": engagement_report,\n",
    "            \"posting_history\": posting_history\n",
    "        }\n",
    "        \n",
    "        analytics_report[\"response_analytics\"] = response_analytics\n",
    "        \n",
    "        print(f\"      Total Responses: {engagement_report.get('total_responses', 0)}\")\n",
    "        print(f\"      Successful Responses: {engagement_report.get('successful_responses', 0)}\")\n",
    "        print(f\"      Success Rate: {posting_history.get('success_rate', 0):.1f}%\")\n",
    "        print(f\"      Total Karma Earned: {engagement_report.get('total_karma_earned', 0)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      Error in response analytics: {str(e)}\")\n",
    "        analytics_report[\"response_analytics\"] = {\"error\": str(e)}\n",
    "    \n",
    "    # 3. RAG Performance Analytics\n",
    "    print(f\"\\n   ü§ñ RAG Performance Analytics\")\n",
    "    try:\n",
    "        # Analyze RAG usage and performance\n",
    "        posted_responses = json_storage.load_data(\"posted_responses.json\")\n",
    "        rag_enabled_responses = [r for r in posted_responses if r.get(\"rag_enabled\", False)]\n",
    "        \n",
    "        # Calculate RAG metrics\n",
    "        total_rag_responses = len(rag_enabled_responses)\n",
    "        successful_rag_responses = len([r for r in rag_enabled_responses if r.get(\"success\", False)])\n",
    "        rag_success_rate = (successful_rag_responses / total_rag_responses * 100) if total_rag_responses > 0 else 0\n",
    "        \n",
    "        # Confidence scores analysis\n",
    "        confidence_scores = [r.get(\"confidence\", 0) for r in rag_enabled_responses if r.get(\"confidence\")]\n",
    "        avg_confidence = statistics.mean(confidence_scores) if confidence_scores else 0\n",
    "        \n",
    "        # Test current RAG performance\n",
    "        test_queries = [\n",
    "            \"python web development\",\n",
    "            \"machine learning best practices\",\n",
    "            \"data science libraries\"\n",
    "        ]\n",
    "        \n",
    "        rag_test_results = []\n",
    "        for query in test_queries:\n",
    "            results = vector_storage.query_documents(\n",
    "                org_id=ORGANIZATION_ID,\n",
    "                query=query,\n",
    "                method=\"semantic\",\n",
    "                top_k=3\n",
    "            )\n",
    "            rag_test_results.append({\n",
    "                \"query\": query,\n",
    "                \"results_count\": len(results),\n",
    "                \"avg_score\": statistics.mean([r.get(\"score\", 0) for r in results]) if results else 0\n",
    "            })\n",
    "        \n",
    "        rag_analytics = {\n",
    "            \"total_rag_responses\": total_rag_responses,\n",
    "            \"successful_rag_responses\": successful_rag_responses,\n",
    "            \"rag_success_rate\": rag_success_rate,\n",
    "            \"average_confidence\": avg_confidence,\n",
    "            \"confidence_scores_count\": len(confidence_scores),\n",
    "            \"rag_test_results\": rag_test_results,\n",
    "            \"haystack_backend\": \"chroma_openai_embeddings\"\n",
    "        }\n",
    "        \n",
    "        analytics_report[\"rag_analytics\"] = rag_analytics\n",
    "        \n",
    "        print(f\"      RAG-Enabled Responses: {total_rag_responses}\")\n",
    "        print(f\"      RAG Success Rate: {rag_success_rate:.1f}%\")\n",
    "        print(f\"      Average Confidence: {avg_confidence:.2f}\")\n",
    "        print(f\"      RAG Test Queries: {len(rag_test_results)} performed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      Error in RAG analytics: {str(e)}\")\n",
    "        analytics_report[\"rag_analytics\"] = {\"error\": str(e)}\n",
    "    \n",
    "    # 4. Workflow Performance Analytics\n",
    "    print(f\"\\n   ‚ö° Workflow Performance Analytics\")\n",
    "    try:\n",
    "        # Analyze the complete workflow performance\n",
    "        workflow_metrics = {\n",
    "            \"ingestion_methods_used\": [\"direct_content\", \"url_scraping\", \"batch_ingestion\"],\n",
    "            \"topic_extraction_method\": \"haystack_semantic_search\",\n",
    "            \"subreddit_discovery_method\": \"rag_enhanced_ranking\",\n",
    "            \"response_generation_method\": \"haystack_rag_context\",\n",
    "            \"posting_workflow\": \"approval_based\",\n",
    "            \"analytics_capabilities\": [\n",
    "                \"document_analytics\",\n",
    "                \"response_analytics\", \n",
    "                \"rag_performance\",\n",
    "                \"real_time_metrics\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Calculate workflow completion rate\n",
    "        workflow_steps = [\n",
    "            analytics_report.get(\"document_analytics\", {}).get(\"total_documents\", 0) > 0,\n",
    "            analytics_report.get(\"rag_analytics\", {}).get(\"rag_test_results\", []),\n",
    "            analytics_report.get(\"response_analytics\", {}).get(\"engagement_report\", {}),\n",
    "        ]\n",
    "        \n",
    "        completed_steps = sum(1 for step in workflow_steps if step)\n",
    "        workflow_completion = (completed_steps / len(workflow_steps)) * 100\n",
    "        \n",
    "        workflow_metrics[\"workflow_completion_rate\"] = workflow_completion\n",
    "        workflow_metrics[\"completed_steps\"] = completed_steps\n",
    "        workflow_metrics[\"total_steps\"] = len(workflow_steps)\n",
    "        \n",
    "        analytics_report[\"workflow_analytics\"] = workflow_metrics\n",
    "        \n",
    "        print(f\"      Workflow Completion: {workflow_completion:.1f}%\")\n",
    "        print(f\"      Completed Steps: {completed_steps}/{len(workflow_steps)}\")\n",
    "        print(f\"      RAG Integration: ‚úÖ Fully Integrated\")\n",
    "        print(f\"      Haystack Backend: ‚úÖ Active\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      Error in workflow analytics: {str(e)}\")\n",
    "        analytics_report[\"workflow_analytics\"] = {\"error\": str(e)}\n",
    "    \n",
    "    # 5. Generate Insights and Recommendations\n",
    "    print(f\"\\n   üí° Insights and Recommendations\")\n",
    "    insights = []\n",
    "    recommendations = []\n",
    "    \n",
    "    # Document insights\n",
    "    doc_analytics = analytics_report.get(\"document_analytics\", {})\n",
    "    if doc_analytics.get(\"total_documents\", 0) > 0:\n",
    "        insights.append(f\"Successfully ingested {doc_analytics['total_documents']} documents using Haystack RAG\")\n",
    "        if doc_analytics.get(\"average_chunks_per_document\", 0) > 10:\n",
    "            recommendations.append(\"Consider optimizing chunk size for better retrieval performance\")\n",
    "    \n",
    "    # RAG insights\n",
    "    rag_analytics = analytics_report.get(\"rag_analytics\", {})\n",
    "    if rag_analytics.get(\"rag_success_rate\", 0) > 80:\n",
    "        insights.append(\"High RAG success rate indicates effective context retrieval\")\n",
    "    elif rag_analytics.get(\"rag_success_rate\", 0) < 60:\n",
    "        recommendations.append(\"Consider improving document quality or adjusting retrieval parameters\")\n",
    "    \n",
    "    if rag_analytics.get(\"average_confidence\", 0) > 0.8:\n",
    "        insights.append(\"High confidence scores suggest good response quality\")\n",
    "    \n",
    "    # Response insights\n",
    "    response_analytics = analytics_report.get(\"response_analytics\", {})\n",
    "    posting_history = response_analytics.get(\"posting_history\", {})\n",
    "    if posting_history.get(\"success_rate\", 0) > 90:\n",
    "        insights.append(\"Excellent posting success rate\")\n",
    "    \n",
    "    analytics_report[\"insights\"] = insights\n",
    "    analytics_report[\"recommendations\"] = recommendations\n",
    "    \n",
    "    for insight in insights:\n",
    "        print(f\"      ‚ú® {insight}\")\n",
    "    \n",
    "    for recommendation in recommendations:\n",
    "        print(f\"      üí° {recommendation}\")\n",
    "    \n",
    "    # 6. Save comprehensive report\n",
    "    analytics_report[\"generated_at\"] = datetime.now().isoformat()\n",
    "    analytics_report[\"organization_id\"] = ORGANIZATION_ID\n",
    "    analytics_report[\"report_version\"] = \"haystack_rag_v1.0\"\n",
    "    \n",
    "    # Save to JSON storage\n",
    "    report_filename = f\"analytics_report_{ORGANIZATION_ID}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    json_storage.save_data(report_filename, analytics_report)\n",
    "    \n",
    "    print(f\"\\nüìã Report Summary:\")\n",
    "    print(f\"   Report saved as: {report_filename}\")\n",
    "    print(f\"   Total sections: {len([k for k in analytics_report.keys() if not k.startswith('generated')])}\")\n",
    "    print(f\"   Insights generated: {len(insights)}\")\n",
    "    print(f\"   Recommendations: {len(recommendations)}\")\n",
    "    \n",
    "    return analytics_report\n",
    "\n",
    "# Run comprehensive analytics\n",
    "final_analytics = await extract_comprehensive_analytics()\n",
    "print(f\"\\n‚úÖ Comprehensive analytics extraction complete!\")\n",
    "print(f\"   Full workflow analytics generated with Haystack RAG integration\")\n",
    "print(f\"   Report includes: Document Analytics, Response Analytics, RAG Performance, and Workflow Metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Workflow Summary and Next Steps\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from src.storage.json_storage import JsonStorage\n",
    "from src.storage.vector_storage import VectorStorage\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-haystack-2024\"\n",
    "\n",
    "# Initialize storage\n",
    "json_storage = JsonStorage()\n",
    "vector_storage = VectorStorage()\n",
    "\n",
    "def display_workflow_summary():\n",
    "    print(\"üéØ Reddit Marketing AI Agent - Workflow Summary\")\n",
    "    print(f\"   Organization: {ORGANIZATION_ID}\")\n",
    "    print(f\"   Completed: {datetime.now()}\")\n",
    "    print(f\"   RAG Backend: Haystack + ChromaDB + OpenAI Embeddings\")\n",
    "    \n",
    "    # Get final statistics\n",
    "    documents = json_storage.filter_items(\"documents.json\", {\"organization_id\": ORGANIZATION_ID})\n",
    "    posted_responses = json_storage.load_data(\"posted_responses.json\")\n",
    "    storage_stats = vector_storage.get_storage_info(ORGANIZATION_ID)\n",
    "    \n",
    "    print(f\"\\nüìä Final Statistics:\")\n",
    "    print(f\"   Documents Ingested: {len(documents)}\")\n",
    "    print(f\"   Total Chunks: {sum(doc.get('chunk_count', 0) for doc in documents)}\")\n",
    "    print(f\"   Responses Generated: {len(posted_responses)}\")\n",
    "    print(f\"   Storage Status: {storage_stats.get('status', 'unknown')}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Completed Workflow Steps:\")\n",
    "    \n",
    "    workflow_steps = [\n",
    "        \"1. Document Ingestion (Multiple Methods)\",\n",
    "        \"   ‚úÖ Direct content ingestion with Haystack\",\n",
    "        \"   ‚úÖ URL scraping and processing\", \n",
    "        \"   ‚úÖ Batch document ingestion\",\n",
    "        \"   ‚úÖ Configurable chunking parameters\",\n",
    "        \"\",\n",
    "        \"2. Topic Extraction using Haystack RAG\",\n",
    "        \"   ‚úÖ Semantic search across documents\",\n",
    "        \"   ‚úÖ Context-aware topic extraction\",\n",
    "        \"   ‚úÖ Document-specific topic analysis\",\n",
    "        \"\",\n",
    "        \"3. Subreddit Discovery and Ranking\",\n",
    "        \"   ‚úÖ RAG-enhanced subreddit ranking\",\n",
    "        \"   ‚úÖ Context-aware relevance scoring\",\n",
    "        \"   ‚úÖ Reddit API integration\",\n",
    "        \"\",\n",
    "        \"4. Post Search and Discovery\",\n",
    "        \"   ‚úÖ Multi-subreddit post searching\",\n",
    "        \"   ‚úÖ Query-based post filtering\",\n",
    "        \"   ‚úÖ Post metadata extraction\",\n",
    "        \"\",\n",
    "        \"5. Post Analysis with Haystack RAG\",\n",
    "        \"   ‚úÖ Context-aware post analysis\",\n",
    "        \"   ‚úÖ Relevance scoring using RAG\",\n",
    "        \"   ‚úÖ Response target selection\",\n",
    "        \"\",\n",
    "        \"6. Response Generation with RAG Context\",\n",
    "        \"   ‚úÖ Haystack semantic search for context\",\n",
    "        \"   ‚úÖ LLM-powered response generation\",\n",
    "        \"   ‚úÖ Confidence scoring and validation\",\n",
    "        \"\",\n",
    "        \"7. Response Posting with Approval\",\n",
    "        \"   ‚úÖ Approval workflow implementation\",\n",
    "        \"   ‚úÖ Response logging and tracking\",\n",
    "        \"   ‚úÖ Error handling and fallbacks\",\n",
    "        \"\",\n",
    "        \"8. Comprehensive Analytics\",\n",
    "        \"   ‚úÖ Document analytics and statistics\",\n",
    "        \"   ‚úÖ Response performance metrics\",\n",
    "        \"   ‚úÖ RAG performance analysis\",\n",
    "        \"   ‚úÖ Workflow completion tracking\",\n",
    "        \"   ‚úÖ Insights and recommendations\"\n",
    "    ]\n",
    "    \n",
    "    for step in workflow_steps:\n",
    "        print(f\"   {step}\")\n",
    "    \n",
    "    print(f\"\\nüîß Technical Implementation Highlights:\")\n",
    "    \n",
    "    technical_features = [\n",
    "        \"‚úÖ Haystack RAG Framework Integration\",\n",
    "        \"‚úÖ ChromaDB Vector Storage with OpenAI Embeddings\",\n",
    "        \"‚úÖ Semantic and Keyword Search Capabilities\",\n",
    "        \"‚úÖ Multi-provider LLM Support (OpenAI, Google, Groq)\",\n",
    "        \"‚úÖ Configurable Chunking and Retrieval Parameters\",\n",
    "        \"‚úÖ Organization-based Document Isolation\",\n",
    "        \"‚úÖ Comprehensive Error Handling and Fallbacks\",\n",
    "        \"‚úÖ Real-time Analytics and Performance Monitoring\",\n",
    "        \"‚úÖ Modular Architecture with Clean Separation\",\n",
    "        \"‚úÖ Independent Cell Execution in Jupyter\"\n",
    "    ]\n",
    "    \n",
    "    for feature in technical_features:\n",
    "        print(f\"   {feature}\")\n",
    "    \n",
    "    print(f\"\\nüöÄ Next Steps and Recommendations:\")\n",
    "    \n",
    "    next_steps = [\n",
    "        \"1. Production Deployment:\",\n",
    "        \"   ‚Ä¢ Set up real Reddit API credentials\",\n",
    "        \"   ‚Ä¢ Configure production-grade vector storage\",\n",
    "        \"   ‚Ä¢ Implement monitoring and alerting\",\n",
    "        \"\",\n",
    "        \"2. Enhanced RAG Capabilities:\",\n",
    "        \"   ‚Ä¢ Experiment with different embedding models\",\n",
    "        \"   ‚Ä¢ Implement hybrid search (semantic + keyword)\",\n",
    "        \"   ‚Ä¢ Add document versioning and updates\",\n",
    "        \"\",\n",
    "        \"3. Advanced Analytics:\",\n",
    "        \"   ‚Ä¢ Real-time karma tracking from Reddit\",\n",
    "        \"   ‚Ä¢ A/B testing for response strategies\",\n",
    "        \"   ‚Ä¢ Performance optimization based on metrics\",\n",
    "        \"\",\n",
    "        \"4. Workflow Automation:\",\n",
    "        \"   ‚Ä¢ Scheduled document ingestion\",\n",
    "        \"   ‚Ä¢ Automated subreddit discovery\",\n",
    "        \"   ‚Ä¢ Smart response approval workflows\",\n",
    "        \"\",\n",
    "        \"5. Scale and Performance:\",\n",
    "        \"   ‚Ä¢ Multi-organization support\",\n",
    "        \"   ‚Ä¢ Distributed processing capabilities\",\n",
    "        \"   ‚Ä¢ Advanced caching strategies\"\n",
    "    ]\n",
    "    \n",
    "    for step in next_steps:\n",
    "        print(f\"   {step}\")\n",
    "    \n",
    "    print(f\"\\nüéâ Workflow Complete!\")\n",
    "    print(f\"   The Reddit Marketing AI Agent with Haystack RAG is fully functional\")\n",
    "    print(f\"   All 8 workflow steps have been successfully demonstrated\")\n",
    "    print(f\"   Ready for production deployment and further customization\")\n",
    "\n",
    "# Display the summary\n",
    "display_workflow_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n",
   "language": "python",\n",
   "name": "python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.0\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 4\n}