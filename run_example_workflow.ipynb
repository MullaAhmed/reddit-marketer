{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Environment Check\n",
      "üìÖ Current Time: 2025-06-22 06:52:19.046431\n",
      "üìÅ Data Directory: data\n",
      "ü§ñ Default Model: gpt-4o\n",
      "üîç Embedding Provider: openai\n",
      "\n",
      "Required API Keys:\n",
      "   ‚úÖ OPENAI_API_KEY: Set\n",
      "   ‚úÖ GOOGLE_API_KEY: Set\n",
      "\n",
      "Optional API Keys:\n",
      "   ‚úÖ GROQ_API_KEY: Set\n",
      "   ‚úÖ FIRECRAWL_API_KEY: Set\n",
      "   ‚ö†Ô∏è LANGCHAIN_PROJECT: Not set\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Environment Check\n",
    "import sys, os\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.core.settings import settings\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üîç Environment Check\")\n",
    "print(f\"üìÖ Current Time: {datetime.now()}\")\n",
    "print(f\"üìÅ Data Directory: {settings.DATA_DIR}\")\n",
    "print(f\"ü§ñ Default Model: {settings.MODEL_NAME}\")\n",
    "print(f\"üîç Embedding Provider: {settings.EMBEDDING_PROVIDER}\")\n",
    "\n",
    "required_keys = {\n",
    "    \"OPENAI_API_KEY\": settings.OPENAI_API_KEY,\n",
    "    \"GOOGLE_API_KEY\": settings.GOOGLE_API_KEY\n",
    "}\n",
    "\n",
    "print(\"\\nRequired API Keys:\")\n",
    "for key, value in required_keys.items():\n",
    "    status = \"‚úÖ\" if value else \"‚ùå\"\n",
    "    print(f\"   {status} {key}: {'Set' if value else 'Missing'}\")\n",
    "\n",
    "optional_keys = {\n",
    "    \"GROQ_API_KEY\": settings.GROQ_API_KEY,\n",
    "    \"FIRECRAWL_API_KEY\": settings.FIRECRAWL_API_KEY,\n",
    "    \"LANGCHAIN_PROJECT\": settings.LANGCHAIN_PROJECT\n",
    "}\n",
    "\n",
    "print(\"\\nOptional API Keys:\")\n",
    "for key, value in optional_keys.items():\n",
    "    status = \"‚úÖ\" if value else \"‚ö†Ô∏è\"\n",
    "    print(f\"   {status} {key}: {'Set' if value else 'Not set'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè¢ Organization Created/Retrieved\n",
      "   Name: Demo Organization\n",
      "   ID: demo-org-2024\n",
      "   Documents: 0\n",
      "   Created: 2025-06-22 01:22:29.034254+00:00\n",
      "   Active: True\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Create Organization\n",
    "import sys\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.services.document_service import DocumentService\n",
    "from app.managers.document_manager import DocumentManager\n",
    "from app.storage.json_storage import JsonStorage\n",
    "from app.storage.vector_storage import VectorStorage\n",
    "from app.clients.storage_client import VectorStorageClient\n",
    "from app.services.scraper_service import WebScraperService\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-2024\"\n",
    "ORGANIZATION_NAME = \"Demo Organization\"\n",
    "\n",
    "# Initialize services\n",
    "json_storage = JsonStorage()\n",
    "vector_storage_client = VectorStorageClient()\n",
    "vector_storage = VectorStorage(vector_storage_client)\n",
    "document_manager = DocumentManager(json_storage)\n",
    "web_scraper_service = WebScraperService()\n",
    "document_service = DocumentService(document_manager, vector_storage, web_scraper_service)\n",
    "\n",
    "# Create organization\n",
    "organization = document_service.get_or_create_organization(ORGANIZATION_ID, ORGANIZATION_NAME)\n",
    "\n",
    "print(f\"üè¢ Organization Created/Retrieved\")\n",
    "print(f\"   Name: {organization.name}\")\n",
    "print(f\"   ID: {organization.id}\")\n",
    "print(f\"   Documents: {organization.documents_count}\")\n",
    "print(f\"   Created: {organization.created_at}\")\n",
    "print(f\"   Active: {organization.is_active}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 1it [00:01,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Direct Content Ingestion\n",
      "   Success: True\n",
      "   Message: Successfully ingested 1 documents (1 chunks)\n",
      "   Document IDs: ['18772b5c-f228-48cb-a517-b10aea55b163']\n",
      "   Documents Ingested: 1\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Ingest Direct Content\n",
    "import sys, os\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.services.document_service import DocumentService\n",
    "from app.managers.document_manager import DocumentManager\n",
    "from app.storage.json_storage import JsonStorage\n",
    "from app.storage.vector_storage import VectorStorage\n",
    "from app.clients.storage_client import VectorStorageClient\n",
    "from app.services.scraper_service import WebScraperService\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-2024\"\n",
    "\n",
    "# Initialize services\n",
    "json_storage = JsonStorage()\n",
    "vector_storage_client = VectorStorageClient()\n",
    "vector_storage = VectorStorage(vector_storage_client)\n",
    "document_manager = DocumentManager(json_storage)\n",
    "web_scraper_service = WebScraperService()\n",
    "document_service = DocumentService(document_manager, vector_storage, web_scraper_service)\n",
    "\n",
    "# Document content\n",
    "documents = [{\n",
    "    \"title\": \"Python Best Practices\",\n",
    "    \"content\": \"\"\"\n",
    "    Python Best Practices for Clean Code\n",
    "    \n",
    "    1. Follow PEP 8 Style Guide\n",
    "    - Use 4 spaces for indentation\n",
    "    - Keep lines under 79 characters\n",
    "    - Use descriptive variable names\n",
    "    \n",
    "    2. Write Docstrings\n",
    "    - Document all functions and classes\n",
    "    - Use triple quotes for docstrings\n",
    "    \n",
    "    3. Use Type Hints\n",
    "    - Add type hints to function parameters\n",
    "    - Use typing module for complex types\n",
    "    \n",
    "    4. Error Handling\n",
    "    - Use specific exception types\n",
    "    - Handle exceptions gracefully\n",
    "    \n",
    "    5. Testing\n",
    "    - Write unit tests for all functions\n",
    "    - Use pytest for testing framework\n",
    "    \"\"\",\n",
    "    \"metadata\": {\"category\": \"programming\", \"language\": \"python\"}\n",
    "}]\n",
    "\n",
    "# Ingest documents\n",
    "success, message, document_ids = document_service.ingest_documents(\n",
    "    documents=documents,\n",
    "    org_id=ORGANIZATION_ID\n",
    ")\n",
    "\n",
    "print(f\"üìÑ Direct Content Ingestion\")\n",
    "print(f\"   Success: {success}\")\n",
    "print(f\"   Message: {message}\")\n",
    "print(f\"   Document IDs: {document_ids}\")\n",
    "print(f\"   Documents Ingested: {len(document_ids) if document_ids else 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 1it [00:01,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê URL Ingestion\n",
      "   URL: https://docs.python.org/3/tutorial/introduction.html\n",
      "   Success: True\n",
      "   Message: Successfully ingested document from URL: https://docs.python.org/3/tutorial/introduction.html\n",
      "   Document ID: 5dea4fc9-8516-4cc9-916c-cc9bfbea2420\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Ingest from URL\n",
    "import sys, os\n",
    "import asyncio\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.services.document_service import DocumentService\n",
    "from app.managers.document_manager import DocumentManager\n",
    "from app.storage.json_storage import JsonStorage\n",
    "from app.storage.vector_storage import VectorStorage\n",
    "from app.clients.storage_client import VectorStorageClient\n",
    "from app.services.scraper_service import WebScraperService\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-2024\"\n",
    "URL_TO_SCRAPE = \"https://docs.python.org/3/tutorial/introduction.html\"\n",
    "\n",
    "# Initialize services\n",
    "json_storage = JsonStorage()\n",
    "vector_storage_client = VectorStorageClient()\n",
    "vector_storage = VectorStorage(vector_storage_client)\n",
    "document_manager = DocumentManager(json_storage)\n",
    "web_scraper_service = WebScraperService()\n",
    "document_service = DocumentService(document_manager, vector_storage, web_scraper_service)\n",
    "\n",
    "# Ingest from URL\n",
    "async def ingest_url():\n",
    "    success, message, document_id = await document_service.ingest_document_from_url(\n",
    "        url=URL_TO_SCRAPE,\n",
    "        organization_id=ORGANIZATION_ID,\n",
    "        title=\"Python Tutorial Introduction\",\n",
    "        scraping_method=\"auto\"\n",
    "    )\n",
    "    \n",
    "    print(f\"üåê URL Ingestion\")\n",
    "    print(f\"   URL: {URL_TO_SCRAPE}\")\n",
    "    print(f\"   Success: {success}\")\n",
    "    print(f\"   Message: {message}\")\n",
    "    print(f\"   Document ID: {document_id}\")\n",
    "\n",
    "# Run the async function\n",
    "await ingest_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Document Query\n",
      "   Query: python best practices\n",
      "   Method: semantic\n",
      "   Results: 3\n",
      "   Processing Time: 952.63ms\n",
      "\n",
      "üìÑ Found Documents:\n",
      "   1. Python Best Practices (Score: 0.817)\n",
      "      Document ID: 18772b5c-f228-48cb-a517-b10aea55b163\n",
      "      Content: Python Best Practices for Clean Code 1. Follow PEP 8 Style Guide - Use 4 spaces for indentation - Ke...\n",
      "   2. Python Tutorial Introduction (Score: 1.242)\n",
      "      Document ID: 5dea4fc9-8516-4cc9-916c-cc9bfbea2420\n",
      "      Content: [printf-style String Formatting](https://docs.python.org/3/library/stdtypes.html#old-string-formatti...\n",
      "   3. Python Tutorial Introduction (Score: 1.267)\n",
      "      Document ID: 5dea4fc9-8516-4cc9-916c-cc9bfbea2420\n",
      "      Content: with a text editor; all decent text editors have an auto-indent facility. When a compound statement ...\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Query Documents\n",
    "import sys, os\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.services.document_service import DocumentService\n",
    "from app.managers.document_manager import DocumentManager\n",
    "from app.storage.json_storage import JsonStorage\n",
    "from app.storage.vector_storage import VectorStorage\n",
    "from app.clients.storage_client import VectorStorageClient\n",
    "from app.services.scraper_service import WebScraperService\n",
    "from app.models.document import DocumentQuery\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-2024\"\n",
    "SEARCH_QUERY = \"python best practices\"\n",
    "\n",
    "# Initialize services\n",
    "json_storage = JsonStorage()\n",
    "vector_storage_client = VectorStorageClient()\n",
    "vector_storage = VectorStorage(vector_storage_client)\n",
    "document_manager = DocumentManager(json_storage)\n",
    "web_scraper_service = WebScraperService()\n",
    "document_service = DocumentService(document_manager, vector_storage, web_scraper_service)\n",
    "\n",
    "# Create query\n",
    "query = DocumentQuery(\n",
    "    query=SEARCH_QUERY,\n",
    "    organization_id=ORGANIZATION_ID,\n",
    "    method=\"semantic\",\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "# Execute query\n",
    "response = document_service.query_documents(query)\n",
    "\n",
    "print(f\"üîç Document Query\")\n",
    "print(f\"   Query: {response.query}\")\n",
    "print(f\"   Method: {response.method}\")\n",
    "print(f\"   Results: {response.total_results}\")\n",
    "print(f\"   Processing Time: {response.processing_time_ms:.2f}ms\")\n",
    "\n",
    "print(f\"\\nüìÑ Found Documents:\")\n",
    "for i, doc in enumerate(response.documents, 1):\n",
    "    print(f\"   {i}. {doc.title} (Score: {doc.score:.3f})\")\n",
    "    print(f\"      Document ID: {doc.document_id}\")\n",
    "    print(f\"      Content: {doc.content[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Campaign Creation\n",
      "   Success: True\n",
      "   Message: Campaign 'Python Community Outreach' created successfully\n",
      "   Campaign ID: 64a74b8f-951a-4ce0-8739-59450c238066\n",
      "   Name: Python Community Outreach\n",
      "   Status: CampaignStatus.CREATED\n",
      "   Tone: ResponseTone.HELPFUL\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Create Campaign\n",
    "import sys, os\n",
    "import asyncio\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.services.campaign_service import CampaignService\n",
    "from app.services.document_service import DocumentService\n",
    "from app.services.reddit_service import RedditService\n",
    "from app.services.llm_service import LLMService\n",
    "from app.managers.campaign_manager import CampaignManager\n",
    "from app.managers.document_manager import DocumentManager\n",
    "from app.storage.json_storage import JsonStorage\n",
    "from app.storage.vector_storage import VectorStorage\n",
    "from app.clients.storage_client import VectorStorageClient\n",
    "from app.clients.llm_client import LLMClient\n",
    "from app.clients.reddit_client import RedditClient\n",
    "from app.services.scraper_service import WebScraperService\n",
    "from app.models.campaign import CampaignCreateRequest, ResponseTone\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-2024\"\n",
    "REDDIT_CREDENTIALS = {\n",
    "    \"client_id\": os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    \"client_secret\": os.getenv(\"REDDIT_CLIENT_SECRET\")\n",
    "}\n",
    "\n",
    "# Initialize services\n",
    "json_storage = JsonStorage()\n",
    "vector_storage_client = VectorStorageClient()\n",
    "vector_storage = VectorStorage(vector_storage_client)\n",
    "document_manager = DocumentManager(json_storage)\n",
    "campaign_manager = CampaignManager(json_storage)\n",
    "web_scraper_service = WebScraperService()\n",
    "document_service = DocumentService(document_manager, vector_storage, web_scraper_service)\n",
    "llm_client = LLMClient()\n",
    "llm_service = LLMService(llm_client)\n",
    "reddit_client = RedditClient(\n",
    "    client_id=REDDIT_CREDENTIALS[\"client_id\"],\n",
    "    client_secret=REDDIT_CREDENTIALS[\"client_secret\"]\n",
    ")\n",
    "reddit_service = RedditService(json_storage, reddit_client)\n",
    "campaign_service = CampaignService(campaign_manager, document_service, reddit_service, llm_service)\n",
    "\n",
    "# Create campaign\n",
    "async def create_campaign():\n",
    "    request = CampaignCreateRequest(\n",
    "        name=\"Python Community Outreach\",\n",
    "        description=\"Engage with Python learning communities\",\n",
    "        response_tone=ResponseTone.HELPFUL,\n",
    "        max_responses_per_day=5\n",
    "    )\n",
    "    \n",
    "    success, message, campaign = await campaign_service.create_campaign(\n",
    "        organization_id=ORGANIZATION_ID,\n",
    "        request=request\n",
    "    )\n",
    "    \n",
    "    print(f\"üéØ Campaign Creation\")\n",
    "    print(f\"   Success: {success}\")\n",
    "    print(f\"   Message: {message}\")\n",
    "    if campaign:\n",
    "        print(f\"   Campaign ID: {campaign.id}\")\n",
    "        print(f\"   Name: {campaign.name}\")\n",
    "        print(f\"   Status: {campaign.status}\")\n",
    "        print(f\"   Tone: {campaign.response_tone}\")\n",
    "    \n",
    "    await campaign_service.cleanup()\n",
    "\n",
    "await create_campaign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Topic Discovery\n",
      "   Success: True\n",
      "   Message: Extracted 20 topics from 2 documents\n",
      "   Topics Found: 20\n",
      "      1. Python\n",
      "      2. Python Tutorial\n",
      "      3. Python Documentation\n",
      "      4. Python Interpreter\n",
      "      5. Python Programming\n",
      "      6. Data Types\n",
      "      7. Numbers\n",
      "      8. Strings\n",
      "      9. Lists\n",
      "      10. Arithmetic Operators\n",
      "      11. Variables\n",
      "      12. Comments\n",
      "      13. Control Flow\n",
      "      14. Functions\n",
      "      15. Modules\n",
      "      16. Error Handling\n",
      "      17. Testing\n",
      "      18. PEP 8\n",
      "      19. Type Hints\n",
      "      20. Docstrings\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Discover Topics\n",
    "import sys, os\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.services.campaign_service import CampaignService\n",
    "from app.services.document_service import DocumentService\n",
    "from app.services.reddit_service import RedditService\n",
    "from app.services.llm_service import LLMService\n",
    "from app.managers.campaign_manager import CampaignManager\n",
    "from app.managers.document_manager import DocumentManager\n",
    "from app.storage.json_storage import JsonStorage\n",
    "from app.storage.vector_storage import VectorStorage\n",
    "from app.clients.storage_client import VectorStorageClient\n",
    "from app.clients.llm_client import LLMClient\n",
    "from app.clients.reddit_client import RedditClient\n",
    "from app.services.scraper_service import WebScraperService\n",
    "from app.models.campaign import SubredditDiscoveryRequest\n",
    "\n",
    "# Configuration - Replace with actual IDs from previous cells\n",
    "CAMPAIGN_ID = \"64a74b8f-951a-4ce0-8739-59450c238066\"  # Replace with actual campaign ID\n",
    "DOCUMENT_IDS = [\"5dea4fc9-8516-4cc9-916c-cc9bfbea2420\",\"18772b5c-f228-48cb-a517-b10aea55b163\"]  # Replace with actual document IDs\n",
    "REDDIT_CREDENTIALS = {\n",
    "    \"client_id\": os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    \"client_secret\": os.getenv(\"REDDIT_CLIENT_SECRET\")\n",
    "}\n",
    "\n",
    "# Initialize services\n",
    "json_storage = JsonStorage()\n",
    "vector_storage_client = VectorStorageClient()\n",
    "vector_storage = VectorStorage(vector_storage_client)\n",
    "document_manager = DocumentManager(json_storage)\n",
    "campaign_manager = CampaignManager(json_storage)\n",
    "web_scraper_service = WebScraperService()\n",
    "document_service = DocumentService(document_manager, vector_storage, web_scraper_service)\n",
    "llm_client = LLMClient()\n",
    "llm_service = LLMService(llm_client)\n",
    "reddit_client = RedditClient(\n",
    "    client_id=REDDIT_CREDENTIALS[\"client_id\"],\n",
    "    client_secret=REDDIT_CREDENTIALS[\"client_secret\"]\n",
    ")\n",
    "reddit_service = RedditService(json_storage, reddit_client)\n",
    "campaign_service = CampaignService(campaign_manager, document_service, reddit_service, llm_service)\n",
    "\n",
    "# Discover topics\n",
    "async def discover_topics():\n",
    "    request = SubredditDiscoveryRequest(document_ids=DOCUMENT_IDS)\n",
    "    \n",
    "    success, message, data = await campaign_service.discover_topics(\n",
    "        campaign_id=CAMPAIGN_ID,\n",
    "        request=request\n",
    "    )\n",
    "    \n",
    "    print(f\"üîç Topic Discovery\")\n",
    "    print(f\"   Success: {success}\")\n",
    "    print(f\"   Message: {message}\")\n",
    "    if data and \"topics\" in data:\n",
    "        print(f\"   Topics Found: {len(data['topics'])}\")\n",
    "        for i, topic in enumerate(data[\"topics\"], 1):\n",
    "            print(f\"      {i}. {topic}\")\n",
    "    \n",
    "    await campaign_service.cleanup()\n",
    "\n",
    "await discover_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Subreddit Discovery\n",
      "   Success: True\n",
      "   Message: Discovered 10 relevant subreddits\n",
      "   Subreddits Found: 10\n",
      "      1. r/Python\n",
      "      2. r/learnpython\n",
      "      3. r/PythonLearning\n",
      "      4. r/PythonProjects2\n",
      "      5. r/pythontips\n",
      "      6. r/PythonJobs\n",
      "      7. r/learnprogramming\n",
      "      8. r/programming\n",
      "      9. r/AskProgramming\n",
      "      10. r/CodingHelp\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Discover Subreddits\n",
    "import sys, os\n",
    "import asyncio\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.services.campaign_service import CampaignService\n",
    "from app.services.document_service import DocumentService\n",
    "from app.services.reddit_service import RedditService\n",
    "from app.services.llm_service import LLMService\n",
    "from app.managers.campaign_manager import CampaignManager\n",
    "from app.managers.document_manager import DocumentManager\n",
    "from app.storage.json_storage import JsonStorage\n",
    "from app.storage.vector_storage import VectorStorage\n",
    "from app.clients.storage_client import VectorStorageClient\n",
    "from app.clients.llm_client import LLMClient\n",
    "from app.clients.reddit_client import RedditClient\n",
    "from app.services.scraper_service import WebScraperService\n",
    "from app.models.campaign import SubredditDiscoveryByTopicsRequest\n",
    "\n",
    "# Configuration\n",
    "CAMPAIGN_ID = \"64a74b8f-951a-4ce0-8739-59450c238066\"  # Replace with actual campaign ID\n",
    "TOPICS = [\"python\", \"programming\", \"coding\", \"software development\"]  # Example topics\n",
    "REDDIT_CREDENTIALS = {\n",
    "    \"client_id\": os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    \"client_secret\": os.getenv(\"REDDIT_CLIENT_SECRET\")\n",
    "}\n",
    "\n",
    "# Initialize services\n",
    "json_storage = JsonStorage()\n",
    "vector_storage_client = VectorStorageClient()\n",
    "vector_storage = VectorStorage(vector_storage_client)\n",
    "document_manager = DocumentManager(json_storage)\n",
    "campaign_manager = CampaignManager(json_storage)\n",
    "web_scraper_service = WebScraperService()\n",
    "document_service = DocumentService(document_manager, vector_storage, web_scraper_service)\n",
    "llm_client = LLMClient()\n",
    "llm_service = LLMService(llm_client)\n",
    "reddit_client = RedditClient(\n",
    "    client_id=REDDIT_CREDENTIALS[\"client_id\"],\n",
    "    client_secret=REDDIT_CREDENTIALS[\"client_secret\"]\n",
    ")\n",
    "reddit_service = RedditService(json_storage, reddit_client)\n",
    "campaign_service = CampaignService(campaign_manager, document_service, reddit_service, llm_service)\n",
    "\n",
    "# Discover subreddits\n",
    "async def discover_subreddits():\n",
    "    request = SubredditDiscoveryByTopicsRequest(topics=TOPICS)\n",
    "    \n",
    "    success, message, data = await campaign_service.discover_subreddits(\n",
    "        campaign_id=CAMPAIGN_ID,\n",
    "        request=request\n",
    "    )\n",
    "    \n",
    "    print(f\"üéØ Subreddit Discovery\")\n",
    "    print(f\"   Success: {success}\")\n",
    "    print(f\"   Message: {message}\")\n",
    "    if data and \"subreddits\" in data:\n",
    "        print(f\"   Subreddits Found: {len(data['subreddits'])}\")\n",
    "        for i, subreddit in enumerate(data[\"subreddits\"], 1):\n",
    "            print(f\"      {i}. r/{subreddit}\")\n",
    "    \n",
    "    await campaign_service.cleanup()\n",
    "\n",
    "await discover_subreddits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Subreddit Search\n",
      "   Query: python programming\n",
      "   Success: True\n",
      "   Message: Found 5 subreddits for 'python programming'\n",
      "   Results: 5\n",
      "\n",
      "üéØ Found Subreddits:\n",
      "   1. r/PythonProgramming (1,520 subscribers)\n",
      "      Description: ...\n",
      "   2. r/Python (1,366,988 subscribers)\n",
      "      Description: The official Python community for Reddit! Stay up to date with the latest news, ...\n",
      "   3. r/PythonLearning (36,420 subscribers)\n",
      "      Description: Everything about learning the programming language Python....\n",
      "   4. r/learnpython (935,779 subscribers)\n",
      "      Description: Subreddit for posting questions and asking for general advice about all topics r...\n",
      "   5. r/programming (6,778,149 subscribers)\n",
      "      Description: Computer Programming...\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Search Subreddits\n",
    "import sys, os\n",
    "import asyncio\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.services.reddit_service import RedditService\n",
    "from app.storage.json_storage import JsonStorage\n",
    "from app.clients.reddit_client import RedditClient\n",
    "\n",
    "# Configuration\n",
    "SEARCH_QUERY = \"python programming\"\n",
    "REDDIT_CREDENTIALS = {\n",
    "    \"client_id\": os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    \"client_secret\": os.getenv(\"REDDIT_CLIENT_SECRET\")\n",
    "}\n",
    "\n",
    "# Initialize services\n",
    "json_storage = JsonStorage()\n",
    "reddit_client = RedditClient(\n",
    "    client_id=REDDIT_CREDENTIALS[\"client_id\"],\n",
    "    client_secret=REDDIT_CREDENTIALS[\"client_secret\"]\n",
    ")\n",
    "reddit_service = RedditService(json_storage, reddit_client)\n",
    "\n",
    "# Search subreddits\n",
    "async def search_subreddits():\n",
    "    success, message, results = await reddit_service.search_subreddits(SEARCH_QUERY, limit=5)\n",
    "    \n",
    "    print(f\"üîç Subreddit Search\")\n",
    "    print(f\"   Query: {SEARCH_QUERY}\")\n",
    "    print(f\"   Success: {success}\")\n",
    "    print(f\"   Message: {message}\")\n",
    "    print(f\"   Results: {len(results) if results else 0}\")\n",
    "    \n",
    "    if results:\n",
    "        print(f\"\\nüéØ Found Subreddits:\")\n",
    "        for i, subreddit in enumerate(results, 1):\n",
    "            print(f\"   {i}. r/{subreddit['name']} ({subreddit['subscribers']:,} subscribers)\")\n",
    "            print(f\"      Description: {subreddit['description'][:80]}...\")\n",
    "    \n",
    "    await reddit_service.cleanup()\n",
    "\n",
    "await search_subreddits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ LLM Response Generation\n",
      "   Prompt: Explain the benefits of using Python for web development\n",
      "   Response Length: 4610 characters\n",
      "\n",
      "üìù Generated Response:\n",
      "   Python has become a popular choice for web development due to its versatility, readability, and extensive ecosystem. Here's a breakdown of the benefits of using Python for web development:\n",
      "\n",
      "**1. Reada...\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Generate LLM Response\n",
    "import sys, os\n",
    "import asyncio\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.services.llm_service import LLMService\n",
    "from app.clients.llm_client import LLMClient\n",
    "\n",
    "# Configuration\n",
    "PROMPT = \"Explain the benefits of using Python for web development\"\n",
    "\n",
    "# Initialize services\n",
    "llm_client = LLMClient()\n",
    "llm_service = LLMService(llm_client)\n",
    "\n",
    "# Generate response\n",
    "async def generate_response():\n",
    "    response = await llm_service.generate_completion(\n",
    "        prompt=PROMPT,\n",
    "        response_format=\"text\",\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    print(f\"ü§ñ LLM Response Generation\")\n",
    "    print(f\"   Prompt: {PROMPT}\")\n",
    "    print(f\"   Response Length: {len(str(response))} characters\")\n",
    "    print(f\"\\nüìù Generated Response:\")\n",
    "    print(f\"   {str(response)[:200]}...\")\n",
    "\n",
    "await generate_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Extract Topics from Content\n",
    "import sys, os\n",
    "import asyncio\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.services.llm_service import LLMService\n",
    "from app.clients.llm_client import LLMClient\n",
    "\n",
    "# Configuration\n",
    "CONTENT = \"\"\"\n",
    "Python is a versatile programming language that's great for web development, \n",
    "data science, machine learning, and automation. It has frameworks like Django \n",
    "and Flask for web development, pandas and numpy for data analysis, and \n",
    "scikit-learn for machine learning. Python is also popular for DevOps and \n",
    "system administration tasks.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize services\n",
    "llm_client = LLMClient()\n",
    "llm_service = LLMService(llm_client)\n",
    "\n",
    "# Extract topics\n",
    "async def extract_topics():\n",
    "    success, message, topics = await llm_service.extract_topics_from_content(CONTENT)\n",
    "    \n",
    "    print(f\"üîç Topic Extraction\")\n",
    "    print(f\"   Success: {success}\")\n",
    "    print(f\"   Message: {message}\")\n",
    "    print(f\"   Topics Found: {len(topics) if topics else 0}\")\n",
    "    \n",
    "    if topics:\n",
    "        print(f\"\\nüìã Extracted Topics:\")\n",
    "        for i, topic in enumerate(topics, 1):\n",
    "            print(f\"   {i}. {topic}\")\n",
    "\n",
    "await extract_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Analytics Dashboard\n",
      "   Organization: demo-org-2024\n",
      "\n",
      "üìà Quick Stats:\n",
      "   Total Campaigns: 1\n",
      "   Active Campaigns: 1\n",
      "   Total Documents: 2\n",
      "   Success Rate: 0.0%\n",
      "\n",
      "üåê Platform Overview:\n",
      "   Total Campaigns: 1\n",
      "   Total Organizations: 1\n",
      "   Active Campaigns: 1\n",
      "   Platform Insights: 1\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Get Analytics\n",
    "import sys, os\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.services.analytics_service import AnalyticsService\n",
    "from app.managers.analytics_manager import AnalyticsManager\n",
    "from app.managers.campaign_manager import CampaignManager\n",
    "from app.managers.document_manager import DocumentManager\n",
    "from app.storage.json_storage import JsonStorage\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-2024\"\n",
    "\n",
    "# Initialize services\n",
    "json_storage = JsonStorage()\n",
    "document_manager = DocumentManager(json_storage)\n",
    "campaign_manager = CampaignManager(json_storage)\n",
    "analytics_manager = AnalyticsManager(campaign_manager, document_manager)\n",
    "analytics_service = AnalyticsService(analytics_manager)\n",
    "\n",
    "# Get analytics\n",
    "quick_stats = analytics_service.get_quick_stats(ORGANIZATION_ID)\n",
    "platform_overview = analytics_service.get_overall_platform_metrics()\n",
    "\n",
    "print(f\"üìä Analytics Dashboard\")\n",
    "print(f\"   Organization: {ORGANIZATION_ID}\")\n",
    "\n",
    "if \"error\" not in quick_stats:\n",
    "    print(f\"\\nüìà Quick Stats:\")\n",
    "    print(f\"   Total Campaigns: {quick_stats.get('total_campaigns', 0)}\")\n",
    "    print(f\"   Active Campaigns: {quick_stats.get('active_campaigns', 0)}\")\n",
    "    print(f\"   Total Documents: {quick_stats.get('total_documents', 0)}\")\n",
    "    print(f\"   Success Rate: {quick_stats.get('success_rate', 0):.1f}%\")\n",
    "\n",
    "if \"error\" not in platform_overview:\n",
    "    campaign_stats = platform_overview.get(\"campaign_stats\", {})\n",
    "    print(f\"\\nüåê Platform Overview:\")\n",
    "    print(f\"   Total Campaigns: {campaign_stats.get('total_campaigns', 0)}\")\n",
    "    print(f\"   Total Organizations: {campaign_stats.get('total_organizations', 0)}\")\n",
    "    print(f\"   Active Campaigns: {campaign_stats.get('active_campaigns', 0)}\")\n",
    "    print(f\"   Platform Insights: {len(platform_overview.get('platform_insights', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: List Organizations\n",
    "import sys, os\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.services.document_service import DocumentService\n",
    "from app.managers.document_manager import DocumentManager\n",
    "from app.storage.json_storage import JsonStorage\n",
    "from app.storage.vector_storage import VectorStorage\n",
    "from app.clients.storage_client import VectorStorageClient\n",
    "from app.services.scraper_service import WebScraperService\n",
    "\n",
    "# Initialize services\n",
    "json_storage = JsonStorage()\n",
    "vector_storage_client = VectorStorageClient()\n",
    "vector_storage = VectorStorage(vector_storage_client)\n",
    "document_manager = DocumentManager(json_storage)\n",
    "web_scraper_service = WebScraperService()\n",
    "document_service = DocumentService(document_manager, vector_storage, web_scraper_service)\n",
    "\n",
    "# List organizations\n",
    "organizations = document_service.list_organizations()\n",
    "\n",
    "print(f\"üè¢ Organizations List\")\n",
    "print(f\"   Total Organizations: {len(organizations)}\")\n",
    "\n",
    "if organizations:\n",
    "    print(f\"\\nüìã Organizations:\")\n",
    "    for i, org in enumerate(organizations, 1):\n",
    "        print(f\"   {i}. {org.name} ({org.id})\")\n",
    "        print(f\"      Documents: {org.documents_count}\")\n",
    "        print(f\"      Created: {org.created_at}\")\n",
    "        print(f\"      Active: {org.is_active}\")\n",
    "else:\n",
    "    print(\"   No organizations found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: List Campaigns\n",
    "import sys, os\n",
    "import asyncio\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.services.campaign_service import CampaignService\n",
    "from app.services.document_service import DocumentService\n",
    "from app.services.reddit_service import RedditService\n",
    "from app.services.llm_service import LLMService\n",
    "from app.managers.campaign_manager import CampaignManager\n",
    "from app.managers.document_manager import DocumentManager\n",
    "from app.storage.json_storage import JsonStorage\n",
    "from app.storage.vector_storage import VectorStorage\n",
    "from app.clients.storage_client import VectorStorageClient\n",
    "from app.clients.llm_client import LLMClient\n",
    "from app.clients.reddit_client import RedditClient\n",
    "from app.services.scraper_service import WebScraperService\n",
    "\n",
    "# Configuration\n",
    "ORGANIZATION_ID = \"demo-org-2024\"\n",
    "REDDIT_CREDENTIALS = {\n",
    "    \"client_id\": os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    \"client_secret\": os.getenv(\"REDDIT_CLIENT_SECRET\")\n",
    "}\n",
    "\n",
    "# Initialize services\n",
    "json_storage = JsonStorage()\n",
    "vector_storage_client = VectorStorageClient()\n",
    "vector_storage = VectorStorage(vector_storage_client)\n",
    "document_manager = DocumentManager(json_storage)\n",
    "campaign_manager = CampaignManager(json_storage)\n",
    "web_scraper_service = WebScraperService()\n",
    "document_service = DocumentService(document_manager, vector_storage, web_scraper_service)\n",
    "llm_client = LLMClient()\n",
    "llm_service = LLMService(llm_client)\n",
    "reddit_client = RedditClient(\n",
    "    client_id=REDDIT_CREDENTIALS[\"client_id\"],\n",
    "    client_secret=REDDIT_CREDENTIALS[\"client_secret\"]\n",
    ")\n",
    "reddit_service = RedditService(json_storage, reddit_client)\n",
    "campaign_service = CampaignService(campaign_manager, document_service, reddit_service, llm_service)\n",
    "\n",
    "# List campaigns\n",
    "async def list_campaigns():\n",
    "    success, message, campaigns = await campaign_service.list_campaigns(ORGANIZATION_ID)\n",
    "    \n",
    "    print(f\"üìã Campaigns List\")\n",
    "    print(f\"   Organization: {ORGANIZATION_ID}\")\n",
    "    print(f\"   Success: {success}\")\n",
    "    print(f\"   Message: {message}\")\n",
    "    print(f\"   Total Campaigns: {len(campaigns) if campaigns else 0}\")\n",
    "    \n",
    "    if campaigns:\n",
    "        print(f\"\\nüéØ Campaigns:\")\n",
    "        for i, campaign in enumerate(campaigns, 1):\n",
    "            print(f\"   {i}. {campaign.name} ({campaign.status})\")\n",
    "            print(f\"      ID: {campaign.id}\")\n",
    "            print(f\"      Created: {campaign.created_at}\")\n",
    "            print(f\"      Tone: {campaign.response_tone}\")\n",
    "    \n",
    "    await campaign_service.cleanup()\n",
    "\n",
    "await list_campaigns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Web Scraping Test\n",
    "import sys, os\n",
    "sys.path.append('app')\n",
    "\n",
    "from app.services.scraper_service import WebScraperService\n",
    "\n",
    "# Configuration\n",
    "TEST_URL = \"https://httpbin.org/html\"  # Simple test URL\n",
    "SCRAPING_METHOD = \"requests\"  # Use requests method for reliability\n",
    "\n",
    "# Initialize service\n",
    "web_scraper = WebScraperService()\n",
    "\n",
    "# Test scraping\n",
    "scraped_content = web_scraper.scrape_url(TEST_URL, method=SCRAPING_METHOD)\n",
    "\n",
    "print(f\"üåê Web Scraping Test\")\n",
    "print(f\"   URL: {TEST_URL}\")\n",
    "print(f\"   Method: {SCRAPING_METHOD}\")\n",
    "print(f\"   Success: {scraped_content is not None}\")\n",
    "\n",
    "if scraped_content:\n",
    "    print(f\"   Content Length: {len(scraped_content)} characters\")\n",
    "    print(f\"\\nüìÑ Content Preview:\")\n",
    "    print(f\"   {scraped_content[:200]}...\")\n",
    "else:\n",
    "    print(f\"   Failed to scrape content\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
