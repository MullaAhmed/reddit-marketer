{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Marketing AI Agent - Complete Example Workflow\n",
    "\n",
    "This notebook demonstrates the complete workflow of the Reddit Marketing AI Agent for a single organization.\n",
    "\n",
    "## Prerequisites\n",
    "1. Ensure your `.env` file is configured with:\n",
    "   - `OPENAI_API_KEY`\n",
    "   - `GOOGLE_API_KEY`\n",
    "   - `GROQ_API_KEY` (optional)\n",
    "   - `FIRECRAWL_API_KEY` (optional)\n",
    "2. Fill in your Reddit API credentials in Cell 2\n",
    "3. Run cells in order for the complete workflow\n",
    "\n",
    "Each cell can be run independently after the initial setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n",
      "üìÅ Data directory: data\n",
      "ü§ñ Default model: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Initial Setup and Imports\n",
    "import os\n",
    "import uuid\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up logging to see service output\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Import models\n",
    "from app.models.campaign import (\n",
    "    CampaignCreateRequest, ResponseTone, SubredditDiscoveryRequest,\n",
    "    PostDiscoveryRequest, ResponseGenerationRequest, ResponseExecutionRequest\n",
    ")\n",
    "from app.models.document import DocumentCreateRequest, DocumentIngestURLRequest\n",
    "\n",
    "# Import settings\n",
    "from app.core.settings import settings\n",
    "\n",
    "# Import services\n",
    "from app.services.campaign_service import CampaignService\n",
    "from app.services.document_service import DocumentService\n",
    "from app.services.reddit_service import RedditService\n",
    "from app.services.llm_service import LLMService\n",
    "from app.services.analytics_service import AnalyticsService\n",
    "from app.services.scraper_service import WebScraperService\n",
    "\n",
    "# Import managers and storage\n",
    "from app.managers.campaign_manager import CampaignManager\n",
    "from app.managers.document_manager import DocumentManager\n",
    "from app.managers.embeddings_manager import EmbeddingsManager\n",
    "from app.managers.analytics_manager import AnalyticsManager\n",
    "from app.storage.json_storage import JsonStorage\n",
    "from app.storage.vector_storage import VectorStorage\n",
    "\n",
    "# Import clients\n",
    "from app.clients.llm_client import LLMClient\n",
    "from app.clients.reddit_client import RedditClient\n",
    "from app.clients.storage_client import VectorStorageClient\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"üìÅ Data directory: {settings.DATA_DIR}\")\n",
    "print(f\"ü§ñ Default model: {settings.MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè¢ Organization ID: example-org\n",
      "üìã Campaign Name: Example Campaign\n",
      "‚úÖ Environment variables configured\n",
      "‚úÖ Reddit credentials configured\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration and Credentials\n",
    "\n",
    "# Generate unique IDs for this workflow\n",
    "ORGANIZATION_ID = f\"example-org\"\n",
    "CAMPAIGN_NAME = f\"Example Campaign\"\n",
    "\n",
    "print(f\"üè¢ Organization ID: {ORGANIZATION_ID}\")\n",
    "print(f\"üìã Campaign Name: {CAMPAIGN_NAME}\")\n",
    "\n",
    "# Reddit API Credentials - FILL THESE IN WITH YOUR ACTUAL CREDENTIALS\n",
    "REDDIT_CREDENTIALS = {\n",
    "    \"client_id\": os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    \"client_secret\": os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "    \"username\": os.getenv(\"REDDIT_USERNAME\"),\n",
    "    \"password\": os.getenv(\"REDDIT_PASSWORD\")\n",
    "}\n",
    "\n",
    "# Validate environment variables\n",
    "required_env_vars = [\"OPENAI_API_KEY\", \"GOOGLE_API_KEY\"]\n",
    "missing_vars = [var for var in required_env_vars if not getattr(settings, var, None)]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"‚ùå Missing required environment variables: {missing_vars}\")\n",
    "    print(\"Please configure your .env file with the required API keys.\")\n",
    "else:\n",
    "    print(\"‚úÖ Environment variables configured\")\n",
    "\n",
    "# Check Reddit credentials\n",
    "if REDDIT_CREDENTIALS[\"client_id\"] == \"YOUR_REDDIT_CLIENT_ID\":\n",
    "    print(\"‚ö†Ô∏è  Please update REDDIT_CREDENTIALS with your actual Reddit API credentials\")\n",
    "    print(\"   You can get these from: https://www.reddit.com/prefs/apps\")\n",
    "else:\n",
    "    print(\"‚úÖ Reddit credentials configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing core components...\n",
      "üîß Initializing managers...\n",
      "üîß Initializing services...\n",
      "‚úÖ All services initialized successfully!\n",
      "üöÄ Ready to start the workflow\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize Services and Dependencies\n",
    "\n",
    "print(\"üîß Initializing core components...\")\n",
    "\n",
    "# Initialize core components\n",
    "json_storage = JsonStorage()\n",
    "vector_storage_client = VectorStorageClient()\n",
    "reddit_client = RedditClient(\n",
    "    client_id=REDDIT_CREDENTIALS[\"client_id\"],\n",
    "    client_secret=REDDIT_CREDENTIALS[\"client_secret\"],\n",
    "    username=REDDIT_CREDENTIALS[\"username\"],\n",
    "    password=REDDIT_CREDENTIALS[\"password\"]\n",
    ")\n",
    "llm_client = LLMClient()\n",
    "web_scraper_service = WebScraperService()\n",
    "\n",
    "print(\"üîß Initializing managers...\")\n",
    "\n",
    "# Initialize managers\n",
    "campaign_manager = CampaignManager(json_storage=json_storage)\n",
    "document_manager = DocumentManager(json_storage=json_storage)\n",
    "embeddings_manager = EmbeddingsManager(vector_storage_client=vector_storage_client)\n",
    "analytics_manager = AnalyticsManager(\n",
    "    campaign_manager=campaign_manager,\n",
    "    document_manager=document_manager\n",
    ")\n",
    "\n",
    "print(\"üîß Initializing services...\")\n",
    "\n",
    "# Initialize services\n",
    "llm_service = LLMService(llm_client=llm_client)\n",
    "reddit_service = RedditService(json_storage=json_storage, reddit_client=reddit_client)\n",
    "vector_storage = VectorStorage(vector_storage_client=vector_storage_client)\n",
    "document_service = DocumentService(\n",
    "    document_manager=document_manager,\n",
    "    vector_storage=vector_storage,\n",
    "    web_scraper_service=web_scraper_service\n",
    ")\n",
    "campaign_service = CampaignService(\n",
    "    campaign_manager=campaign_manager,\n",
    "    document_service=document_service,\n",
    "    reddit_service=reddit_service,\n",
    "    llm_service=llm_service\n",
    ")\n",
    "analytics_service = AnalyticsService(analytics_manager=analytics_manager)\n",
    "\n",
    "print(\"‚úÖ All services initialized successfully!\")\n",
    "print(\"üöÄ Ready to start the workflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè¢ Setting up organization: example-org\n",
      "‚úÖ Organization created/retrieved:\n",
      "   ID: example-org\n",
      "   Name: Example Organization 2025-06-21\n",
      "   Description: Auto-created organization for example-org\n",
      "   Documents: 0\n",
      "   Created: 2025-06-21 01:18:57.185311+00:00\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Set up Organization\n",
    "\n",
    "print(f\"üè¢ Setting up organization: {ORGANIZATION_ID}\")\n",
    "\n",
    "# Create or get organization\n",
    "organization = document_service.get_or_create_organization(\n",
    "    org_id=ORGANIZATION_ID,\n",
    "    org_name=f\"Example Organization {datetime.now().strftime('%Y-%m-%d')}\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Organization created/retrieved:\")\n",
    "print(f\"   ID: {organization.id}\")\n",
    "print(f\"   Name: {organization.name}\")\n",
    "print(f\"   Description: {organization.description}\")\n",
    "print(f\"   Documents: {organization.documents_count}\")\n",
    "print(f\"   Created: {organization.created_at}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Ingesting document with direct content...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 0it [00:00, ?it/s]2025-06-21 06:48:58,638 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Calculating embeddings: 1it [00:01,  1.17s/it]\n",
      "2025-06-21 06:48:58,926 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-06-21 06:48:59,221 - app.clients.storage_client - INFO - Stored 1 documents for org example-org\n",
      "2025-06-21 06:48:59,221 - app.storage.vector_storage - INFO - Stored 1 chunks for document e1937129-43ec-46d4-9a0f-27deb0ba2471\n",
      "2025-06-21 06:48:59,237 - app.services.document_service - INFO - Ingested 1 documents (1 chunks) for org example-org\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully ingested 1 documents (1 chunks)\n",
      "   Document ID: e1937129-43ec-46d4-9a0f-27deb0ba2471\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Ingest Document - Direct Content\n",
    "\n",
    "print(\"üìÑ Ingesting document with direct content...\")\n",
    "\n",
    "# Sample content about Python programming\n",
    "sample_content = \"\"\"\n",
    "Python Programming Best Practices and Tips\n",
    "\n",
    "Python is a versatile and powerful programming language that's perfect for beginners and experts alike. \n",
    "Here are some essential tips and best practices for Python development:\n",
    "\n",
    "1. Code Readability: Python emphasizes readable code. Use meaningful variable names, proper indentation, \n",
    "   and follow PEP 8 style guidelines.\n",
    "\n",
    "2. Virtual Environments: Always use virtual environments to manage dependencies and avoid conflicts \n",
    "   between different projects.\n",
    "\n",
    "3. Error Handling: Use try-except blocks to handle exceptions gracefully. This makes your code more \n",
    "   robust and user-friendly.\n",
    "\n",
    "4. List Comprehensions: Use list comprehensions for creating lists in a more Pythonic way. \n",
    "   They're often more readable and efficient than traditional loops.\n",
    "\n",
    "5. Documentation: Write docstrings for your functions and classes. Good documentation helps other \n",
    "   developers (and future you) understand your code.\n",
    "\n",
    "6. Testing: Write unit tests for your code using frameworks like pytest or unittest. \n",
    "   Testing ensures your code works as expected and helps catch bugs early.\n",
    "\n",
    "7. Package Management: Use pip and requirements.txt to manage your project dependencies. \n",
    "   This makes it easy for others to install and run your code.\n",
    "\n",
    "8. Code Organization: Structure your projects with proper modules and packages. \n",
    "   This makes your code more maintainable and reusable.\n",
    "\n",
    "Remember, the key to becoming a better Python programmer is practice and continuous learning. \n",
    "Join Python communities, contribute to open source projects, and keep experimenting with new features and libraries.\n",
    "\"\"\"\n",
    "\n",
    "# Create document request\n",
    "doc_request = DocumentCreateRequest(\n",
    "    title=\"Python Programming Best Practices\",\n",
    "    content=sample_content,\n",
    "    metadata={\n",
    "        \"category\": \"programming\",\n",
    "        \"language\": \"python\",\n",
    "        \"type\": \"tutorial\",\n",
    "        \"source\": \"direct_input\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ingest the document\n",
    "success, message, document_ids = document_service.ingest_documents(\n",
    "    documents=[doc_request.model_dump()],\n",
    "    org_id=ORGANIZATION_ID\n",
    ")\n",
    "\n",
    "if success:\n",
    "    direct_content_doc_id = document_ids[0]\n",
    "    print(f\"‚úÖ {message}\")\n",
    "    print(f\"   Document ID: {direct_content_doc_id}\")\n",
    "else:\n",
    "    print(f\"‚ùå {message}\")\n",
    "    direct_content_doc_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Ingesting document from simulated file upload...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 0it [00:00, ?it/s]2025-06-21 06:48:59,938 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Calculating embeddings: 1it [00:00,  1.43it/s]\n",
      "2025-06-21 06:48:59,970 - app.clients.storage_client - INFO - Stored 1 documents for org example-org\n",
      "2025-06-21 06:48:59,970 - app.storage.vector_storage - INFO - Stored 1 chunks for document 3d91be1f-33be-4ba6-b053-29ce43edd06d\n",
      "2025-06-21 06:48:59,986 - app.services.document_service - INFO - Ingested 1 documents (1 chunks) for org example-org\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully ingested 1 documents (1 chunks)\n",
      "   Document ID: 3d91be1f-33be-4ba6-b053-29ce43edd06d\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Ingest Document - Simulated File Upload\n",
    "\n",
    "print(\"üìÅ Ingesting document from simulated file upload...\")\n",
    "\n",
    "# Simulate file content about web development\n",
    "file_content = \"\"\"\n",
    "Modern Web Development with Python\n",
    "\n",
    "Web development with Python has become increasingly popular due to powerful frameworks like Django, \n",
    "Flask, and FastAPI. Here's a comprehensive guide to modern Python web development:\n",
    "\n",
    "Frameworks Overview:\n",
    "- Django: A high-level framework that encourages rapid development and clean design. Perfect for \n",
    "  large applications with built-in admin interface, ORM, and authentication.\n",
    "- Flask: A lightweight and flexible micro-framework that gives you more control over components. \n",
    "  Great for smaller applications and APIs.\n",
    "- FastAPI: A modern framework for building APIs with automatic documentation and type hints. \n",
    "  Excellent performance and developer experience.\n",
    "\n",
    "Key Concepts:\n",
    "1. MVC Architecture: Understand Model-View-Controller pattern for organizing your code.\n",
    "2. RESTful APIs: Design clean and intuitive APIs following REST principles.\n",
    "3. Database Integration: Use ORMs like SQLAlchemy or Django ORM for database operations.\n",
    "4. Authentication & Authorization: Implement secure user authentication and permission systems.\n",
    "5. Frontend Integration: Connect your Python backend with modern frontend frameworks.\n",
    "\n",
    "Best Practices:\n",
    "- Use environment variables for configuration\n",
    "- Implement proper error handling and logging\n",
    "- Write comprehensive tests for your endpoints\n",
    "- Use database migrations for schema changes\n",
    "- Implement caching for better performance\n",
    "- Follow security best practices (HTTPS, input validation, etc.)\n",
    "\n",
    "Deployment:\n",
    "Modern deployment options include Docker containers, cloud platforms like AWS, Google Cloud, \n",
    "or Heroku, and serverless functions for specific use cases.\n",
    "\"\"\"\n",
    "\n",
    "# Create document request for file upload simulation\n",
    "file_doc_request = DocumentCreateRequest(\n",
    "    title=\"Modern Web Development with Python\",\n",
    "    content=file_content,\n",
    "    metadata={\n",
    "        \"category\": \"web_development\",\n",
    "        \"language\": \"python\",\n",
    "        \"type\": \"guide\",\n",
    "        \"source\": \"file_upload\",\n",
    "        \"filename\": \"web_development_guide.txt\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ingest the document\n",
    "success, message, document_ids = document_service.ingest_documents(\n",
    "    documents=[file_doc_request.model_dump()],\n",
    "    org_id=ORGANIZATION_ID\n",
    ")\n",
    "\n",
    "if success:\n",
    "    file_upload_doc_id = document_ids[0]\n",
    "    print(f\"‚úÖ {message}\")\n",
    "    print(f\"   Document ID: {file_upload_doc_id}\")\n",
    "else:\n",
    "    print(f\"‚ùå {message}\")\n",
    "    file_upload_doc_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 06:49:00,015 - app.services.document_service - INFO - Starting URL ingestion for https://realpython.com/python-basics/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Ingesting document from URL scraping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 06:49:02,409 - app.services.scraper_service - INFO - Successfully scraped https://realpython.com/python-basics/ with Firecrawl\n",
      "Calculating embeddings: 0it [00:00, ?it/s]2025-06-21 06:49:03,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Calculating embeddings: 1it [00:01,  1.38s/it]\n",
      "2025-06-21 06:49:03,892 - app.clients.storage_client - INFO - Stored 6 documents for org example-org\n",
      "2025-06-21 06:49:03,893 - app.storage.vector_storage - INFO - Stored 6 chunks for document 0a85770c-8adf-4cde-a3d3-828abfda4c46\n",
      "2025-06-21 06:49:03,905 - app.services.document_service - INFO - Ingested 1 documents (6 chunks) for org example-org\n",
      "2025-06-21 06:49:03,906 - app.services.document_service - INFO - Successfully ingested document from URL https://realpython.com/python-basics/ with ID 0a85770c-8adf-4cde-a3d3-828abfda4c46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully ingested document from URL: https://realpython.com/python-basics/\n",
      "   Document ID: 0a85770c-8adf-4cde-a3d3-828abfda4c46\n",
      "   Source URL: https://realpython.com/python-basics/\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Ingest Document - URL Scraping\n",
    "\n",
    "print(\"üåê Ingesting document from URL scraping...\")\n",
    "\n",
    "# Example URL - using a public article about Python\n",
    "# Note: Replace with a real URL that you want to scrape\n",
    "EXAMPLE_URL = \"https://realpython.com/python-basics/\"\n",
    "\n",
    "# Create URL ingestion request\n",
    "url_request = DocumentIngestURLRequest(\n",
    "    url=EXAMPLE_URL,\n",
    "    title=\"Python Basics from Real Python\",\n",
    "    organization_id=ORGANIZATION_ID,\n",
    "    scraping_method=\"auto\",  # Will try Firecrawl first, then fallback to requests\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "# Attempt to ingest from URL\n",
    "try:\n",
    "    success, message, url_doc_id = await document_service.ingest_document_from_url(\n",
    "        url=url_request.url,\n",
    "        organization_id=url_request.organization_id,\n",
    "        title=url_request.title,\n",
    "        chunk_size=url_request.chunk_size,\n",
    "        chunk_overlap=url_request.chunk_overlap,\n",
    "        scraping_method=url_request.scraping_method\n",
    "    )\n",
    "    \n",
    "    if success:\n",
    "        print(f\"‚úÖ {message}\")\n",
    "        print(f\"   Document ID: {url_doc_id}\")\n",
    "        print(f\"   Source URL: {EXAMPLE_URL}\")\n",
    "    else:\n",
    "        print(f\"‚ùå URL scraping failed: {message}\")\n",
    "        print(\"   This might be due to missing API keys or network issues\")\n",
    "        url_doc_id = None\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during URL scraping: {str(e)}\")\n",
    "    print(\"   Continuing with other documents...\")\n",
    "    url_doc_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 06:49:03,921 - app.services.campaign_service - INFO - Created campaign 'Example Campaign' for org example-org\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Creating campaign: Example Campaign\n",
      "‚úÖ Campaign 'Example Campaign' created successfully\n",
      "   Campaign ID: 022b52d5-4fc3-481d-9eef-fd8618709b5a\n",
      "   Status: CampaignStatus.CREATED\n",
      "   Response Tone: ResponseTone.HELPFUL\n",
      "   Max Responses/Day: 5\n",
      "   Created: 2025-06-21 01:19:03.916494+00:00\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Create Campaign\n",
    "\n",
    "print(f\"üìã Creating campaign: {CAMPAIGN_NAME}\")\n",
    "\n",
    "# Create campaign request\n",
    "campaign_request = CampaignCreateRequest(\n",
    "    name=CAMPAIGN_NAME,\n",
    "    description=\"Example campaign demonstrating Python programming expertise and web development knowledge\",\n",
    "    response_tone=ResponseTone.HELPFUL,\n",
    "    max_responses_per_day=5\n",
    ")\n",
    "\n",
    "# Create the campaign\n",
    "success, message, campaign = await campaign_service.create_campaign(\n",
    "    organization_id=ORGANIZATION_ID,\n",
    "    request=campaign_request\n",
    ")\n",
    "\n",
    "if success:\n",
    "    CAMPAIGN_ID = campaign.id\n",
    "    print(f\"‚úÖ {message}\")\n",
    "    print(f\"   Campaign ID: {CAMPAIGN_ID}\")\n",
    "    print(f\"   Status: {campaign.status}\")\n",
    "    print(f\"   Response Tone: {campaign.response_tone}\")\n",
    "    print(f\"   Max Responses/Day: {campaign.max_responses_per_day}\")\n",
    "    print(f\"   Created: {campaign.created_at}\")\n",
    "else:\n",
    "    print(f\"‚ùå {message}\")\n",
    "    CAMPAIGN_ID = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 06:49:03,964 - app.services.document_service - INFO - Campaign context prepared: 11860 characters from 3 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Discovering topics and subreddits...\n",
      "üìÑ Using 3 documents for discovery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 06:49:04,179 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:49:05,668 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:49:05,705 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:49:05,711 - app.services.llm_service - INFO - Extracted 10 topics from content\n",
      "2025-06-21 06:49:05,713 - app.clients.reddit_client - INFO - Initialized Reddit API client with user: lonlionli\n",
      "2025-06-21 06:54:10,575 - app.clients.reddit_client - WARNING - Error: received 403 HTTP response. Retrying in 2.00 seconds...\n",
      "2025-06-21 06:55:09,375 - app.clients.reddit_client - WARNING - Error: received 403 HTTP response. Retrying in 4.00 seconds...\n",
      "2025-06-21 06:55:14,195 - app.clients.reddit_client - WARNING - Error: received 403 HTTP response. Retrying in 8.00 seconds...\n",
      "2025-06-21 06:55:22,690 - app.clients.reddit_client - ERROR - Max retries reached: received 403 HTTP response\n",
      "2025-06-21 06:55:22,690 - app.clients.reddit_client - ERROR - Error getting info for r/focschallenges: received 403 HTTP response\n",
      "2025-06-21 06:55:22,690 - app.services.reddit_service - ERROR - Error searching subreddits for topic 'Python courses': received 403 HTTP response\n",
      "2025-06-21 06:55:22,690 - app.clients.reddit_client - INFO - Closed Reddit API client\n",
      "2025-06-21 06:55:22,690 - app.services.reddit_service - INFO - Discovered 77 subreddits for 10 topics\n",
      "2025-06-21 06:55:22,690 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:55:24,287 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:55:24,289 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:55:24,289 - app.services.llm_service - INFO - Ranked 10 subreddits by relevance\n",
      "2025-06-21 06:55:24,291 - app.services.campaign_service - INFO - Discovered 10 subreddits for campaign 022b52d5-4fc3-481d-9eef-fd8618709b5a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Discovered 10 relevant subreddits\n",
      "   Topics found: ['Python programming', 'Web development with Python', 'Django framework', 'Flask framework', 'FastAPI framework', 'Python best practices', 'Python tutorials', 'Python courses', 'Python for beginners', 'Python communities']\n",
      "   Subreddits discovered: ['Python', 'learnpython', 'PythonLearning', 'PythonProjects2', 'pythoncoding', 'django', 'djangolearning', 'flask', 'FastAPI', 'ProgrammingLanguages']\n",
      "   Total subreddits: 10\n",
      "   Campaign status: CampaignStatus.SUBREDDITS_DISCOVERED\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Discover Topics and Subreddits\n",
    "\n",
    "if CAMPAIGN_ID:\n",
    "    print(\"üîç Discovering topics and subreddits...\")\n",
    "    \n",
    "    # Collect all successfully ingested document IDs\n",
    "    document_ids = []\n",
    "    if direct_content_doc_id:\n",
    "        document_ids.append(direct_content_doc_id)\n",
    "    if file_upload_doc_id:\n",
    "        document_ids.append(file_upload_doc_id)\n",
    "    if url_doc_id:\n",
    "        document_ids.append(url_doc_id)\n",
    "    \n",
    "    if not document_ids:\n",
    "        print(\"‚ùå No documents available for subreddit discovery\")\n",
    "    else:\n",
    "        print(f\"üìÑ Using {len(document_ids)} documents for discovery\")\n",
    "        \n",
    "        # Create subreddit discovery request\n",
    "        subreddit_request = SubredditDiscoveryRequest(\n",
    "            document_ids=document_ids\n",
    "        )\n",
    "        \n",
    "        # Discover subreddits\n",
    "        campaign, campaign_context, topics = await campaign_service.discover_topics(\n",
    "            campaign_id=CAMPAIGN_ID,\n",
    "            request=subreddit_request\n",
    "        )\n",
    "\n",
    "        success, message, discovery_data = await campaign_service.discover_subreddits(\n",
    "            campaign, campaign_context, topics\n",
    "\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            print(f\"‚úÖ {message}\")\n",
    "            print(f\"   Topics found: {discovery_data.get('topics', [])}\")\n",
    "            print(f\"   Subreddits discovered: {discovery_data.get('subreddits', [])}\")\n",
    "            print(f\"   Total subreddits: {discovery_data.get('total_found', 0)}\")\n",
    "            \n",
    "            # Get updated campaign\n",
    "            success, _, updated_campaign = await campaign_service.get_campaign(CAMPAIGN_ID)\n",
    "            if success:\n",
    "                campaign = updated_campaign\n",
    "                print(f\"   Campaign status: {campaign.status}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {message}\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot discover subreddits - no campaign created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if CAMPAIGN_ID:\n",
    "    print(\"üîç Discovering topics and subreddits...\")\n",
    "       \n",
    "        success, message, discovery_data = await campaign_service.discover_subreddits(\n",
    "            campaign, campaign_context, topics\n",
    "\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            print(f\"‚úÖ {message}\")\n",
    "            print(f\"   Topics found: {discovery_data.get('topics', [])}\")\n",
    "            print(f\"   Subreddits discovered: {discovery_data.get('subreddits', [])}\")\n",
    "            print(f\"   Total subreddits: {discovery_data.get('total_found', 0)}\")\n",
    "            \n",
    "            # Get updated campaign\n",
    "            success, _, updated_campaign = await campaign_service.get_campaign(CAMPAIGN_ID)\n",
    "            if success:\n",
    "                campaign = updated_campaign\n",
    "                print(f\"   Campaign status: {campaign.status}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {message}\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot discover subreddits - no campaign created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 06:55:24,320 - app.services.document_service - INFO - Campaign context prepared: 11860 characters from 3 documents\n",
      "2025-06-21 06:55:24,321 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Discovering relevant posts...\n",
      "üéØ Targeting subreddits: ['Python', 'learnpython', 'PythonLearning']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 06:55:25,439 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:55:25,488 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:55:25,488 - app.services.llm_service - INFO - Extracted 10 topics from content\n",
      "2025-06-21 06:55:25,495 - app.clients.reddit_client - INFO - Initialized Reddit API client with user: lonlionli\n",
      "2025-06-21 06:56:23,156 - app.clients.reddit_client - INFO - Closed Reddit API client\n",
      "2025-06-21 06:56:23,157 - app.services.reddit_service - INFO - Discovered 37 posts across 3 subreddits\n",
      "2025-06-21 06:56:23,157 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:24,662 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:24,663 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:24,665 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:26,100 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:26,158 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:26,159 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:27,479 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:27,547 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:27,547 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:28,858 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:28,915 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:28,916 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:30,325 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:30,379 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:30,380 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:31,589 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:31,641 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:31,643 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:32,866 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:32,925 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:32,926 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:34,183 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:34,239 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:34,239 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:35,502 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:35,561 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:35,562 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:36,892 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:36,951 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:36,953 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:38,204 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:38,258 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:38,259 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:39,515 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:39,598 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:39,599 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:40,934 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:40,986 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:40,986 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:42,249 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:42,303 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:42,303 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:43,509 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:43,571 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:43,572 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:45,045 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:45,099 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:45,099 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:46,531 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:46,585 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:46,585 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:47,929 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:47,994 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:47,995 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:49,326 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:49,379 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:49,380 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:50,644 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:50,700 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:50,707 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:51,920 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:51,973 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:51,975 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:53,225 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:53,279 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:53,280 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:54,449 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:54,503 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:54,503 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:55,739 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:55,791 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:55,792 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:57,112 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:57,161 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:57,161 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:58,421 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:58,477 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:58,478 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:56:59,638 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:56:59,701 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:56:59,701 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:57:00,939 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:57:00,995 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:57:00,996 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:57:02,261 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:57:02,323 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:57:02,323 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:57:03,695 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:57:03,757 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:57:03,759 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:57:04,900 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:57:04,953 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:57:04,954 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:57:06,088 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:57:06,139 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:57:06,140 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:57:07,474 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:57:07,522 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:57:07,522 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:57:08,931 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:57:08,979 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:57:08,979 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:57:10,374 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:57:10,443 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:57:10,443 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:57:11,721 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:57:11,774 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:57:11,775 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:57:13,057 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:57:13,121 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:57:13,125 - app.services.campaign_service - INFO - Found 37 relevant posts for campaign 022b52d5-4fc3-481d-9eef-fd8618709b5a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 37 relevant posts\n",
      "   Posts found: 37\n",
      "   Subreddits searched: 3\n",
      "\n",
      "üìã Sample discovered posts:\n",
      "   1. Saturday Daily Thread: Resource Request and Sharing! Daily T...\n",
      "      Subreddit: r/Python\n",
      "      Score: 3\n",
      "      Relevance: 0.90\n",
      "   2. package-ui.nvim now supports pip/python...\n",
      "      Subreddit: r/Python\n",
      "      Score: 6\n",
      "      Relevance: 0.80\n",
      "   3. Mom Java is eating my AI lunch...\n",
      "      Subreddit: r/Python\n",
      "      Score: 0\n",
      "      Relevance: 0.70\n",
      "\n",
      "   Campaign status: CampaignStatus.POSTS_FOUND\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Discover Posts\n",
    "\n",
    "if CAMPAIGN_ID and campaign and campaign.target_subreddits:\n",
    "    print(\"üìù Discovering relevant posts...\")\n",
    "    \n",
    "    # Use discovered subreddits (limit to first 3 for demo)\n",
    "    target_subreddits = campaign.target_subreddits[:3]\n",
    "    print(f\"üéØ Targeting subreddits: {target_subreddits}\")\n",
    "    \n",
    "    # Create post discovery request\n",
    "    post_request = PostDiscoveryRequest(\n",
    "        subreddits=target_subreddits,\n",
    "        max_posts_per_subreddit=5,  # Limit for demo\n",
    "        time_filter=\"day\",\n",
    "        reddit_credentials=REDDIT_CREDENTIALS\n",
    "    )\n",
    "    \n",
    "    # Discover posts\n",
    "    try:\n",
    "        success, message, post_data = await campaign_service.discover_posts(\n",
    "            campaign_id=CAMPAIGN_ID,\n",
    "            request=post_request\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            print(f\"‚úÖ {message}\")\n",
    "            print(f\"   Posts found: {post_data.get('posts_found', 0)}\")\n",
    "            print(f\"   Subreddits searched: {post_data.get('subreddits_searched', 0)}\")\n",
    "            \n",
    "            # Show sample posts\n",
    "            posts = post_data.get('posts', [])\n",
    "            if posts:\n",
    "                print(\"\\nüìã Sample discovered posts:\")\n",
    "                for i, post in enumerate(posts[:3]):  # Show first 3\n",
    "                    print(f\"   {i+1}. {post.get('title', 'No title')[:60]}...\")\n",
    "                    print(f\"      Subreddit: r/{post.get('subreddit', 'unknown')}\")\n",
    "                    print(f\"      Score: {post.get('score', 0)}\")\n",
    "                    print(f\"      Relevance: {post.get('relevance_score', 0):.2f}\")\n",
    "            \n",
    "            # Get updated campaign\n",
    "            success, _, updated_campaign = await campaign_service.get_campaign(CAMPAIGN_ID)\n",
    "            if success:\n",
    "                campaign = updated_campaign\n",
    "                print(f\"\\n   Campaign status: {campaign.status}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {message}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error discovering posts: {str(e)}\")\n",
    "        print(\"   This might be due to Reddit API credentials or rate limiting\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Cannot discover posts - no campaign or subreddits available\")\n",
    "    if CAMPAIGN_ID:\n",
    "        print(\"   Make sure subreddit discovery completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 06:57:13,157 - app.services.document_service - INFO - Campaign context prepared: 11860 characters from 3 documents\n",
      "2025-06-21 06:57:13,159 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Generating responses for target posts...\n",
      "üéØ Generating responses for 3 posts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 06:57:15,372 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:57:15,420 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:57:15,427 - app.services.llm_service - INFO - Generated response with confidence: 0.90\n",
      "2025-06-21 06:57:15,427 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:57:17,247 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:57:17,301 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:57:17,302 - app.services.llm_service - INFO - Generated response with confidence: 0.90\n",
      "2025-06-21 06:57:17,303 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-21 06:57:19,855 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-21 06:57:19,903 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "2025-06-21 06:57:19,909 - app.services.llm_service - INFO - Generated response with confidence: 0.90\n",
      "2025-06-21 06:57:19,910 - app.services.campaign_service - INFO - Generated 3 responses for campaign 022b52d5-4fc3-481d-9eef-fd8618709b5a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generated 3 responses\n",
      "   Responses generated: 3\n",
      "\n",
      "üí¨ Sample generated responses:\n",
      "\n",
      "   Response 1:\n",
      "   Target Post: 0ef9f540-69b9-4045-9...\n",
      "   Confidence: 0.90\n",
      "   Content Preview: Great initiative with this resource sharing thread! For those just starting out and looking for a ro...\n",
      "\n",
      "   Response 2:\n",
      "   Target Post: 642b0ebe-327f-42df-8...\n",
      "   Confidence: 0.90\n",
      "   Content Preview: This looks like a really useful tool, especially for those working with multiple languages and packa...\n",
      "\n",
      "   Campaign status: CampaignStatus.RESPONSES_PLANNED\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Generate Responses\n",
    "\n",
    "if CAMPAIGN_ID and campaign and campaign.target_posts:\n",
    "    print(\"üí¨ Generating responses for target posts...\")\n",
    "    \n",
    "    # Select first few posts for response generation (limit for demo)\n",
    "    target_post_ids = list(campaign.target_posts.keys())[:3]\n",
    "    print(f\"üéØ Generating responses for {len(target_post_ids)} posts\")\n",
    "    \n",
    "    # Create response generation request\n",
    "    response_request = ResponseGenerationRequest(\n",
    "        target_post_ids=target_post_ids,\n",
    "        tone=ResponseTone.HELPFUL  # Override campaign tone if needed\n",
    "    )\n",
    "    \n",
    "    # Generate responses\n",
    "    try:\n",
    "        success, message, response_data = await campaign_service.generate_responses(\n",
    "            campaign_id=CAMPAIGN_ID,\n",
    "            request=response_request\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            print(f\"‚úÖ {message}\")\n",
    "            print(f\"   Responses generated: {response_data.get('responses_generated', 0)}\")\n",
    "            \n",
    "            # Show sample responses\n",
    "            responses = response_data.get('responses', [])\n",
    "            if responses:\n",
    "                print(\"\\nüí¨ Sample generated responses:\")\n",
    "                for i, response in enumerate(responses[:2]):  # Show first 2\n",
    "                    print(f\"\\n   Response {i+1}:\")\n",
    "                    print(f\"   Target Post: {response.get('target_post_id', 'unknown')[:20]}...\")\n",
    "                    print(f\"   Confidence: {response.get('confidence_score', 0):.2f}\")\n",
    "                    print(f\"   Content Preview: {response.get('response_content', '')[:100]}...\")\n",
    "            \n",
    "            # Get updated campaign\n",
    "            success, _, updated_campaign = await campaign_service.get_campaign(CAMPAIGN_ID)\n",
    "            if success:\n",
    "                campaign = updated_campaign\n",
    "                print(f\"\\n   Campaign status: {campaign.status}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {message}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating responses: {str(e)}\")\n",
    "        print(\"   This might be due to LLM API issues or rate limiting\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Cannot generate responses - no campaign or target posts available\")\n",
    "    if CAMPAIGN_ID:\n",
    "        print(\"   Make sure post discovery completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Response posting is disabled for safety\n",
      "   3 responses are ready to post\n",
      "   Set ACTUALLY_POST_TO_REDDIT = True to enable actual posting\n",
      "   ‚ö†Ô∏è  WARNING: This will make real posts to Reddit!\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Post Responses (CAUTION: This will actually post to Reddit!)\n",
    "\n",
    "# WARNING: This cell will actually post responses to Reddit!\n",
    "# Only run this if you want to make real posts\n",
    "ACTUALLY_POST_TO_REDDIT = False  # Set to True to enable actual posting\n",
    "\n",
    "if CAMPAIGN_ID and campaign and campaign.planned_responses and ACTUALLY_POST_TO_REDDIT:\n",
    "    print(\"üöÄ Posting responses to Reddit...\")\n",
    "    print(\"‚ö†Ô∏è  WARNING: This will make actual posts to Reddit!\")\n",
    "    \n",
    "    # Select first few planned responses (limit for demo)\n",
    "    planned_response_ids = list(campaign.planned_responses.keys())[:2]\n",
    "    print(f\"üì§ Posting {len(planned_response_ids)} responses\")\n",
    "    \n",
    "    # Create response execution request\n",
    "    execution_request = ResponseExecutionRequest(\n",
    "        planned_response_ids=planned_response_ids,\n",
    "        reddit_credentials=REDDIT_CREDENTIALS\n",
    "    )\n",
    "    \n",
    "    # Execute responses\n",
    "    try:\n",
    "        success, message, execution_data = await campaign_service.execute_responses(\n",
    "            campaign_id=CAMPAIGN_ID,\n",
    "            request=execution_request\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            print(f\"‚úÖ {message}\")\n",
    "            print(f\"   Responses posted: {execution_data.get('responses_posted', 0)}\")\n",
    "            print(f\"   Responses failed: {execution_data.get('responses_failed', 0)}\")\n",
    "            \n",
    "            # Show posting results\n",
    "            posted_responses = execution_data.get('posted_responses', [])\n",
    "            if posted_responses:\n",
    "                print(\"\\nüì§ Posting results:\")\n",
    "                for i, response in enumerate(posted_responses):\n",
    "                    status = \"‚úÖ Success\" if response.get('posting_successful') else \"‚ùå Failed\"\n",
    "                    print(f\"   {i+1}. {status}\")\n",
    "                    if response.get('posting_successful'):\n",
    "                        print(f\"      Reddit ID: {response.get('reddit_comment_id', 'unknown')}\")\n",
    "                        print(f\"      Permalink: {response.get('reddit_permalink', 'unknown')}\")\n",
    "                    else:\n",
    "                        print(f\"      Error: {response.get('error_message', 'Unknown error')}\")\n",
    "            \n",
    "            # Get updated campaign\n",
    "            success, _, updated_campaign = await campaign_service.get_campaign(CAMPAIGN_ID)\n",
    "            if success:\n",
    "                campaign = updated_campaign\n",
    "                print(f\"\\n   Campaign status: {campaign.status}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {message}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error posting responses: {str(e)}\")\n",
    "        print(\"   This might be due to Reddit API issues or authentication problems\")\n",
    "        \n",
    "elif CAMPAIGN_ID and campaign and campaign.planned_responses:\n",
    "    print(\"‚ö†Ô∏è  Response posting is disabled for safety\")\n",
    "    print(f\"   {len(campaign.planned_responses)} responses are ready to post\")\n",
    "    print(\"   Set ACTUALLY_POST_TO_REDDIT = True to enable actual posting\")\n",
    "    print(\"   ‚ö†Ô∏è  WARNING: This will make real posts to Reddit!\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot post responses - no campaign or planned responses available\")\n",
    "    if CAMPAIGN_ID:\n",
    "        print(\"   Make sure response generation completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Fetching analytics and reports...\n",
      "\n",
      "üè¢ Organization Quick Stats:\n",
      "   Total Campaigns: 1\n",
      "   Active Campaigns: 1\n",
      "   Total Documents: 3\n",
      "   Success Rate: 0.0%\n",
      "\n",
      "üìã Campaign Engagement Report:\n",
      "   Campaign: Example Campaign\n",
      "   Status: CampaignStatus.RESPONSES_PLANNED\n",
      "   Documents Selected: 3\n",
      "   Subreddits Found: 10\n",
      "   Posts Found: 37\n",
      "   Responses Planned: 3\n",
      "   Responses Posted: 0\n",
      "   Successful Posts: 0\n",
      "   Failed Posts: 0\n",
      "   Engagement Rate: 8.1%\n",
      "   Success Rate: 0.0%\n",
      "\n",
      "üéØ Subreddit Effectiveness Report:\n",
      "   Total Subreddits Analyzed: 3\n",
      "   Top Performing Subreddits:\n",
      "     1. r/Python (Score: 15.0)\n",
      "        Posts Targeted: 12\n",
      "        Engagement Rate: 25.0%\n",
      "     2. r/learnpython (Score: 0.0)\n",
      "        Posts Targeted: 16\n",
      "        Engagement Rate: 0.0%\n",
      "     3. r/PythonLearning (Score: 0.0)\n",
      "        Posts Targeted: 9\n",
      "        Engagement Rate: 0.0%\n",
      "   Recommendations:\n",
      "     ‚Ä¢ r/PythonLearning shows low effectiveness - review targeting strategy\n",
      "\n",
      "üìà Organization Performance Report:\n",
      "   Performance Insights:\n",
      "     ‚Ä¢ Low success rate suggests need for response quality improvement\n",
      "     ‚Ä¢ Low engagement rate indicates need for better post selection\n",
      "\n",
      "‚úÖ Analytics report complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Fetch and Display Analytics\n",
    "\n",
    "if CAMPAIGN_ID:\n",
    "    print(\"üìä Fetching analytics and reports...\")\n",
    "    \n",
    "    # Get organization quick stats\n",
    "    print(\"\\nüè¢ Organization Quick Stats:\")\n",
    "    try:\n",
    "        quick_stats = analytics_service.get_quick_stats(ORGANIZATION_ID)\n",
    "        if \"error\" not in quick_stats:\n",
    "            print(f\"   Total Campaigns: {quick_stats.get('total_campaigns', 0)}\")\n",
    "            print(f\"   Active Campaigns: {quick_stats.get('active_campaigns', 0)}\")\n",
    "            print(f\"   Total Documents: {quick_stats.get('total_documents', 0)}\")\n",
    "            print(f\"   Success Rate: {quick_stats.get('success_rate', 0):.1f}%\")\n",
    "        else:\n",
    "            print(f\"   Error: {quick_stats['error']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Error fetching quick stats: {str(e)}\")\n",
    "    \n",
    "    # Get campaign engagement report\n",
    "    print(\"\\nüìã Campaign Engagement Report:\")\n",
    "    try:\n",
    "        engagement_report = analytics_service.get_campaign_engagement_report(CAMPAIGN_ID)\n",
    "        if \"error\" not in engagement_report:\n",
    "            basic_stats = engagement_report.get('basic_stats', {})\n",
    "            engagement_metrics = engagement_report.get('engagement_metrics', {})\n",
    "            \n",
    "            print(f\"   Campaign: {basic_stats.get('campaign_name', 'Unknown')}\")\n",
    "            print(f\"   Status: {basic_stats.get('status', 'Unknown')}\")\n",
    "            print(f\"   Documents Selected: {basic_stats.get('documents_selected', 0)}\")\n",
    "            print(f\"   Subreddits Found: {basic_stats.get('subreddits_found', 0)}\")\n",
    "            print(f\"   Posts Found: {basic_stats.get('posts_found', 0)}\")\n",
    "            print(f\"   Responses Planned: {basic_stats.get('responses_planned', 0)}\")\n",
    "            print(f\"   Responses Posted: {basic_stats.get('responses_posted', 0)}\")\n",
    "            print(f\"   Successful Posts: {basic_stats.get('successful_posts', 0)}\")\n",
    "            print(f\"   Failed Posts: {basic_stats.get('failed_posts', 0)}\")\n",
    "            \n",
    "            if engagement_metrics:\n",
    "                print(f\"   Engagement Rate: {engagement_metrics.get('engagement_rate', 0):.1f}%\")\n",
    "                print(f\"   Success Rate: {engagement_metrics.get('success_rate', 0):.1f}%\")\n",
    "        else:\n",
    "            print(f\"   Error: {engagement_report['error']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Error fetching engagement report: {str(e)}\")\n",
    "    \n",
    "    # Get subreddit effectiveness report\n",
    "    print(\"\\nüéØ Subreddit Effectiveness Report:\")\n",
    "    try:\n",
    "        subreddit_report = analytics_service.get_subreddit_effectiveness_report(ORGANIZATION_ID)\n",
    "        if \"error\" not in subreddit_report:\n",
    "            ranked_subreddits = subreddit_report.get('ranked_subreddits', [])\n",
    "            recommendations = subreddit_report.get('recommendations', [])\n",
    "            \n",
    "            print(f\"   Total Subreddits Analyzed: {subreddit_report.get('total_subreddits_analyzed', 0)}\")\n",
    "            \n",
    "            if ranked_subreddits:\n",
    "                print(\"   Top Performing Subreddits:\")\n",
    "                for i, subreddit in enumerate(ranked_subreddits[:3]):\n",
    "                    name = subreddit.get('subreddit', 'unknown')\n",
    "                    score = subreddit.get('effectiveness_score', 0)\n",
    "                    stats = subreddit.get('stats', {})\n",
    "                    print(f\"     {i+1}. r/{name} (Score: {score:.1f})\")\n",
    "                    print(f\"        Posts Targeted: {stats.get('posts_targeted', 0)}\")\n",
    "                    print(f\"        Engagement Rate: {stats.get('engagement_rate', 0):.1f}%\")\n",
    "            \n",
    "            if recommendations:\n",
    "                print(\"   Recommendations:\")\n",
    "                for rec in recommendations:\n",
    "                    print(f\"     ‚Ä¢ {rec}\")\n",
    "        else:\n",
    "            print(f\"   Error: {subreddit_report['error']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Error fetching subreddit report: {str(e)}\")\n",
    "    \n",
    "    # Get organization performance report\n",
    "    print(\"\\nüìà Organization Performance Report:\")\n",
    "    try:\n",
    "        performance_report = analytics_service.get_organization_performance_report(ORGANIZATION_ID)\n",
    "        if \"error\" not in performance_report:\n",
    "            insights = performance_report.get('performance_insights', [])\n",
    "            \n",
    "            if insights:\n",
    "                print(\"   Performance Insights:\")\n",
    "                for insight in insights:\n",
    "                    print(f\"     ‚Ä¢ {insight}\")\n",
    "            else:\n",
    "                print(\"   No specific insights available yet\")\n",
    "                print(\"   (More data needed for detailed analysis)\")\n",
    "        else:\n",
    "            print(f\"   Error: {performance_report['error']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Error fetching performance report: {str(e)}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Analytics report complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot fetch analytics - no campaign available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Cleaning up resources...\n",
      "‚úÖ Reddit client cleaned up\n",
      "‚úÖ Campaign service cleaned up\n",
      "\n",
      "üìã Workflow Summary:\n",
      "   Organization ID: example-org\n",
      "   Campaign ID: 022b52d5-4fc3-481d-9eef-fd8618709b5a\n",
      "   Campaign Name: Example Campaign\n",
      "   ‚úÖ Direct content document: e1937129-43ec-46d4-9a0f-27deb0ba2471\n",
      "   ‚úÖ File upload document: 3d91be1f-33be-4ba6-b053-29ce43edd06d\n",
      "   ‚úÖ URL scraped document: 0a85770c-8adf-4cde-a3d3-828abfda4c46\n",
      "   Total documents ingested: 3\n",
      "   Campaign status: CampaignStatus.RESPONSES_PLANNED\n",
      "   Subreddits discovered: 10\n",
      "   Posts found: 37\n",
      "   Responses planned: 3\n",
      "   Responses posted: 0\n",
      "\n",
      "üéâ Example workflow completed!\n",
      "\n",
      "üìù Notes:\n",
      "   ‚Ä¢ Data is stored in the 'data' directory\n",
      "   ‚Ä¢ You can run individual cells to repeat specific steps\n",
      "   ‚Ä¢ To reset, delete the 'data' directory and restart\n",
      "   ‚Ä¢ Check the API documentation at http://localhost:8000/docs when running the server\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Cleanup and Summary\n",
    "\n",
    "print(\"üßπ Cleaning up resources...\")\n",
    "\n",
    "# Cleanup Reddit service\n",
    "try:\n",
    "    await reddit_service.cleanup()\n",
    "    print(\"‚úÖ Reddit client cleaned up\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error during Reddit cleanup: {str(e)}\")\n",
    "\n",
    "# Cleanup campaign service\n",
    "try:\n",
    "    await campaign_service.cleanup()\n",
    "    print(\"‚úÖ Campaign service cleaned up\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error during campaign cleanup: {str(e)}\")\n",
    "\n",
    "print(\"\\nüìã Workflow Summary:\")\n",
    "print(f\"   Organization ID: {ORGANIZATION_ID}\")\n",
    "if CAMPAIGN_ID:\n",
    "    print(f\"   Campaign ID: {CAMPAIGN_ID}\")\n",
    "    print(f\"   Campaign Name: {CAMPAIGN_NAME}\")\n",
    "else:\n",
    "    print(\"   Campaign: Not created\")\n",
    "\n",
    "# Document ingestion summary\n",
    "doc_count = 0\n",
    "if direct_content_doc_id:\n",
    "    doc_count += 1\n",
    "    print(f\"   ‚úÖ Direct content document: {direct_content_doc_id}\")\n",
    "if file_upload_doc_id:\n",
    "    doc_count += 1\n",
    "    print(f\"   ‚úÖ File upload document: {file_upload_doc_id}\")\n",
    "if url_doc_id:\n",
    "    doc_count += 1\n",
    "    print(f\"   ‚úÖ URL scraped document: {url_doc_id}\")\n",
    "\n",
    "print(f\"   Total documents ingested: {doc_count}\")\n",
    "\n",
    "# Campaign progress summary\n",
    "if campaign:\n",
    "    print(f\"   Campaign status: {campaign.status}\")\n",
    "    print(f\"   Subreddits discovered: {len(campaign.target_subreddits)}\")\n",
    "    print(f\"   Posts found: {len(campaign.target_posts)}\")\n",
    "    print(f\"   Responses planned: {len(campaign.planned_responses)}\")\n",
    "    print(f\"   Responses posted: {len(campaign.posted_responses)}\")\n",
    "\n",
    "print(\"\\nüéâ Example workflow completed!\")\n",
    "print(\"\\nüìù Notes:\")\n",
    "print(\"   ‚Ä¢ Data is stored in the 'data' directory\")\n",
    "print(\"   ‚Ä¢ You can run individual cells to repeat specific steps\")\n",
    "print(\"   ‚Ä¢ To reset, delete the 'data' directory and restart\")\n",
    "print(\"   ‚Ä¢ Check the API documentation at http://localhost:8000/docs when running the server\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
